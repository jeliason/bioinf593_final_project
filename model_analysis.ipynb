{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = pd.read_excel('./CRC_TMAs_patient_annotations.xlsx')\n",
    "cell_data = pd.read_csv('./CRC_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"label\"\n",
    "CENTROID = \"centroid\"\n",
    "FEATURES = \"feat\"\n",
    "def data_to_dgl_graph(pt_data, cell_data, k=5, thresh=50, mode=\"distance\", normalize=False):\n",
    "    labs, ids = np.unique(cell_data.loc[:,'ClusterName'].to_numpy(), return_inverse=True)\n",
    "    cell_data['ClusterID'] = ids\n",
    "    graphs = []\n",
    "    patients = []\n",
    "    targets = []\n",
    "    for spot in cell_data[\"spots\"].unique():\n",
    "        subset = cell_data.loc[cell_data.loc[:,'spots'] == spot,:]\n",
    "        features = subset.loc[:,'size':'Treg-PD-1+'].to_numpy() # TODO: This step depends on column order\n",
    "        if normalize:\n",
    "            features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
    "        centroids = subset.loc[:,'X':'Y'].to_numpy()\n",
    "        annotation = subset.loc[:,'ClusterID'].to_numpy()\n",
    "        num_nodes = features.shape[0]\n",
    "        graph = dgl.DGLGraph()\n",
    "        graph.add_nodes(num_nodes)\n",
    "        graph.ndata[CENTROID] = torch.FloatTensor(centroids)\n",
    "        graph.ndata[FEATURES] = torch.FloatTensor(features)\n",
    "        if annotation is not None:\n",
    "            graph.ndata[LABEL] = torch.FloatTensor(annotation.astype(float))\n",
    "        adj = kneighbors_graph(\n",
    "            centroids,\n",
    "            k,\n",
    "            mode=mode,\n",
    "            include_self=False,\n",
    "            metric=\"euclidean\").toarray()\n",
    "        if thresh is not None:\n",
    "            adj[adj > thresh] = 0\n",
    "        edge_list = np.nonzero(adj)\n",
    "        graph.add_edges(list(edge_list[0]), list(edge_list[1]))\n",
    "        graphs.append(graph)\n",
    "        assert(len(subset['patients'].unique()) == 1)\n",
    "        patients.append(subset['patients'].unique()[0])\n",
    "    for pt in patients:\n",
    "        cp = pt_data.loc[pt_data.loc[:,'Patient'] == pt,'cp_TNM_Simple'].values[0]\n",
    "        assert(cp == 3.0 or cp == 4.0)\n",
    "        t = 0 if cp == 3.0 else 1\n",
    "        targets.append(t)\n",
    "    return list(zip(graphs,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import trange\n",
    "from histocartography.ml import CellGraphModel\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate(batch):\n",
    "    g = dgl.batch([example[0] for example in batch])\n",
    "    l = torch.LongTensor([example[1] for example in batch])\n",
    "    return g, l\n",
    "\n",
    "def dataset_split(data, val_prop):\n",
    "    if val_prop == 0:\n",
    "        return data, data\n",
    "    random.shuffle(data)\n",
    "    train_data = data[:int(len(data)*val_prop)]\n",
    "    val_data = data[int(len(data)*val_prop):]\n",
    "    return train_data, val_data\n",
    "\n",
    "#TODO: More sophisticated oversample\n",
    "def oversample_positive(data, oversample_factor=2):\n",
    "    negative = []\n",
    "    positive = []\n",
    "    for item in data:\n",
    "        if item[1] == 0:\n",
    "            negative.append(item)\n",
    "        else:\n",
    "            positive.append(item)\n",
    "    positive = oversample_factor*positive\n",
    "    return positive+negative\n",
    "\n",
    "class CGModel():\n",
    "    def __init__(self, gnn_params, classification_params, node_dim, num_classes=2, lr=10e-3, weight_decay=5e-4, num_epochs=50, batch_size=8):\n",
    "        self.gnn_params = gnn_params\n",
    "        self.classification_params = classification_params\n",
    "        self.node_dim = node_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.cgm = CellGraphModel(gnn_params, classification_params, node_dim, num_classes=2)\n",
    "\n",
    "    def train(self, data, val_prop=0, oversample_factor=1):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.cgm.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "        # define loss function\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        # training\n",
    "        loss = 10e5\n",
    "        val_accuracy = 0.\n",
    "        train_dataloader = None\n",
    "        val_dataloader = None\n",
    "        loss_list = []\n",
    "        val_accuracy_list = []\n",
    "        train_data, val_data = dataset_split(data, val_prop)\n",
    "        train_data = oversample_positive(train_data, oversample_factor=oversample_factor)\n",
    "        train_dataloader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True, collate_fn=collate)\n",
    "        val_dataloader = DataLoader(val_data, batch_size=self.batch_size, shuffle=True, collate_fn=collate)\n",
    "        with trange(self.num_epochs) as t:\n",
    "            for epoch in t:\n",
    "                t.set_description('Loss={} | Val Accuracy={}'.format(loss, val_accuracy))\n",
    "                self.cgm.train()\n",
    "                for graphs, labels in train_dataloader:\n",
    "                    logits = self.cgm(graphs)\n",
    "                    loss = loss_fn(logits, labels)\n",
    "                    loss_list.append(loss.item())\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                self.cgm.eval()\n",
    "                all_val_logits = []\n",
    "                all_val_labels = []\n",
    "                for graphs, labels in val_dataloader:\n",
    "                    with torch.no_grad():\n",
    "                        logits = self.cgm(graphs)\n",
    "                    all_val_logits.append(logits)\n",
    "                    all_val_labels.append(labels)\n",
    "                all_val_logits = torch.cat(all_val_logits).cpu()\n",
    "                all_val_labels = torch.cat(all_val_labels).cpu()\n",
    "                with torch.no_grad():\n",
    "                    _, predictions = torch.max(all_val_logits, dim=1)\n",
    "                    correct = torch.sum(predictions.to(int) == all_val_labels.to(int))\n",
    "                    val_accuracy = round(correct.item() * 1.0 / len(all_val_labels), 2)\n",
    "                    val_accuracy_list.append(val_accuracy)\n",
    "        return loss_list, val_accuracy_list\n",
    "    \n",
    "    def infer(self, graphs):\n",
    "        with torch.no_grad():\n",
    "            logits = self.cgm(graphs)\n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            return predictions\n",
    "    \n",
    "    def test(self, graphs, labels):\n",
    "        predictions = self.infer(graphs)\n",
    "        with torch.no_grad():\n",
    "            correct = torch.sum(predictions.to(int) == labels.to(int))\n",
    "            accuracy = round(correct.item() * 1.0 / len(labels), 2)\n",
    "            return accuracy\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        #TODO: Save model and params to model path\n",
    "        pass\n",
    "\n",
    "    def load(self, model_path):\n",
    "        #TODO: Load model cpt and params from model path\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_params = {\n",
    "    'readout_op': 'concat',\n",
    "    'layer_type': 'gin_layer',\n",
    "    'output_dim': 32,\n",
    "    'num_layers': 2,\n",
    "    'readout_type': 'mean'\n",
    "}\n",
    "classification_params = {\n",
    "    'hidden_dim': 20,\n",
    "    'num_layers': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_to_dgl_graph(pt_data, cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_connectivity = data_to_dgl_graph(pt_data, cell_data, mode='connectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n"
     ]
    }
   ],
   "source": [
    "data_normalized = data_to_dgl_graph(pt_data, cell_data, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n",
      "<ipython-input-25-00cfefa17e0b>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  features = np.nan_to_num((features-features.mean(axis=0))/features.std(axis=0))\n"
     ]
    }
   ],
   "source": [
    "data_connectivity_normalized = data_to_dgl_graph(pt_data, cell_data, mode='connectivity', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGLGraph(num_nodes=1164, num_edges=4376,\n",
       "         ndata_schemes={'centroid': Scheme(shape=(2,), dtype=torch.float32), 'feat': Scheme(shape=(74,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.float32)}\n",
       "         edata_schemes={})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CGModel(gnn_params=gnn_params, classification_params=classification_params, node_dim=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = CGModel(gnn_params=gnn_params, classification_params=classification_params, node_dim=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = CGModel(gnn_params=gnn_params, classification_params=classification_params, node_dim=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = CGModel(gnn_params=gnn_params, classification_params=classification_params, node_dim=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in range(140)]\n",
    "random.shuffle(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = [data_normalized[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:int(0.7*len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = data[int(0.7*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_n = data_normalized[:int(0.7*len(data_normalized))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_n = data_normalized[int(0.7*len(data_normalized)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0742134377360344 | Val Accuracy=0.81: 100%|| 50/50 [02:43<00:00,  3.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7690851092338562,\n",
       "  0.6768689155578613,\n",
       "  0.6784200072288513,\n",
       "  0.6837761402130127,\n",
       "  0.6159120798110962,\n",
       "  0.6042351126670837,\n",
       "  0.4625478982925415,\n",
       "  0.6881422996520996,\n",
       "  0.671578586101532,\n",
       "  0.4934389293193817,\n",
       "  0.6558221578598022,\n",
       "  0.36913788318634033,\n",
       "  0.311375230550766,\n",
       "  0.543473482131958,\n",
       "  0.3475882411003113,\n",
       "  0.8856189846992493,\n",
       "  0.2745167016983032,\n",
       "  0.6793084144592285,\n",
       "  0.44746026396751404,\n",
       "  0.7713050842285156,\n",
       "  0.38245290517807007,\n",
       "  0.4539937376976013,\n",
       "  0.5816279053688049,\n",
       "  0.4315859079360962,\n",
       "  0.32880041003227234,\n",
       "  0.9481697082519531,\n",
       "  0.38149407505989075,\n",
       "  0.4808424711227417,\n",
       "  0.25085386633872986,\n",
       "  0.46043655276298523,\n",
       "  0.8204863667488098,\n",
       "  0.45188987255096436,\n",
       "  0.5232120156288147,\n",
       "  0.8172386884689331,\n",
       "  0.3242320716381073,\n",
       "  0.6124542355537415,\n",
       "  0.46108993887901306,\n",
       "  0.39130762219429016,\n",
       "  0.24776208400726318,\n",
       "  0.3441516160964966,\n",
       "  0.44966983795166016,\n",
       "  0.4313836395740509,\n",
       "  0.8623785972595215,\n",
       "  0.8348249197006226,\n",
       "  0.26569539308547974,\n",
       "  0.2605861723423004,\n",
       "  0.35143178701400757,\n",
       "  0.7545347809791565,\n",
       "  0.7724987864494324,\n",
       "  0.48084333539009094,\n",
       "  0.5619891881942749,\n",
       "  0.19464266300201416,\n",
       "  0.4180886447429657,\n",
       "  0.43035364151000977,\n",
       "  0.24956291913986206,\n",
       "  0.5353193283081055,\n",
       "  0.472495973110199,\n",
       "  0.8729784488677979,\n",
       "  0.28016045689582825,\n",
       "  0.2953961491584778,\n",
       "  0.5614794492721558,\n",
       "  0.477277934551239,\n",
       "  0.5941027402877808,\n",
       "  0.5635837912559509,\n",
       "  1.0819923877716064,\n",
       "  0.5260997414588928,\n",
       "  0.3040037751197815,\n",
       "  0.35103639960289,\n",
       "  0.33844947814941406,\n",
       "  0.7343029975891113,\n",
       "  0.35585254430770874,\n",
       "  0.3640071749687195,\n",
       "  0.647952675819397,\n",
       "  0.7578710317611694,\n",
       "  0.40886881947517395,\n",
       "  0.5069339871406555,\n",
       "  0.4594070315361023,\n",
       "  0.40358486771583557,\n",
       "  0.34117481112480164,\n",
       "  0.5425915718078613,\n",
       "  0.3553093373775482,\n",
       "  0.7108467221260071,\n",
       "  0.34558355808258057,\n",
       "  0.8058680295944214,\n",
       "  0.44326651096343994,\n",
       "  0.2948632538318634,\n",
       "  0.2842015027999878,\n",
       "  0.4197741448879242,\n",
       "  0.3483141362667084,\n",
       "  0.3688063621520996,\n",
       "  0.22325287759304047,\n",
       "  0.28259798884391785,\n",
       "  0.3926304578781128,\n",
       "  0.2901013195514679,\n",
       "  0.23641568422317505,\n",
       "  0.4887966811656952,\n",
       "  0.3280525803565979,\n",
       "  1.6413655281066895,\n",
       "  0.4792693555355072,\n",
       "  0.31997957825660706,\n",
       "  0.34037041664123535,\n",
       "  0.5740888714790344,\n",
       "  0.27442628145217896,\n",
       "  0.24449481070041656,\n",
       "  0.8968062400817871,\n",
       "  0.19019287824630737,\n",
       "  0.6642572283744812,\n",
       "  0.3995685875415802,\n",
       "  0.43530330061912537,\n",
       "  0.33640122413635254,\n",
       "  0.3542088270187378,\n",
       "  0.3149779736995697,\n",
       "  0.8815476894378662,\n",
       "  0.305625319480896,\n",
       "  0.3730286955833435,\n",
       "  0.3616584837436676,\n",
       "  0.33280542492866516,\n",
       "  0.29677098989486694,\n",
       "  0.355959951877594,\n",
       "  0.43180176615715027,\n",
       "  0.4274887144565582,\n",
       "  0.2684980630874634,\n",
       "  0.1763458102941513,\n",
       "  0.5007524490356445,\n",
       "  0.3168465197086334,\n",
       "  0.3413084149360657,\n",
       "  0.29061537981033325,\n",
       "  0.752031683921814,\n",
       "  0.5220507383346558,\n",
       "  0.5504360198974609,\n",
       "  1.028507113456726,\n",
       "  0.2982448935508728,\n",
       "  0.3536734879016876,\n",
       "  0.22235046327114105,\n",
       "  0.47033604979515076,\n",
       "  0.30988872051239014,\n",
       "  0.32588887214660645,\n",
       "  0.37317898869514465,\n",
       "  0.2774651348590851,\n",
       "  0.5814119577407837,\n",
       "  0.28051239252090454,\n",
       "  0.2192731499671936,\n",
       "  0.293403685092926,\n",
       "  0.23669877648353577,\n",
       "  0.21520382165908813,\n",
       "  0.2854423522949219,\n",
       "  0.3266823887825012,\n",
       "  0.21132560074329376,\n",
       "  0.7693792581558228,\n",
       "  0.806315541267395,\n",
       "  0.4994531571865082,\n",
       "  0.31745707988739014,\n",
       "  0.5277993679046631,\n",
       "  0.27177679538726807,\n",
       "  0.733065128326416,\n",
       "  0.2127910554409027,\n",
       "  0.2176884263753891,\n",
       "  0.20643694698810577,\n",
       "  0.2650607228279114,\n",
       "  1.0263302326202393,\n",
       "  0.13324762880802155,\n",
       "  1.250164270401001,\n",
       "  0.7578706741333008,\n",
       "  0.2518466114997864,\n",
       "  0.5267784595489502,\n",
       "  0.4989005923271179,\n",
       "  0.662886917591095,\n",
       "  0.362076073884964,\n",
       "  0.7409908175468445,\n",
       "  0.32196617126464844,\n",
       "  0.4384080767631531,\n",
       "  0.8578753471374512,\n",
       "  0.27070096135139465,\n",
       "  0.43340885639190674,\n",
       "  0.7409103512763977,\n",
       "  0.3733859658241272,\n",
       "  0.3425690829753876,\n",
       "  0.3740186393260956,\n",
       "  0.3138086199760437,\n",
       "  0.3060213327407837,\n",
       "  0.4066708981990814,\n",
       "  0.5128125548362732,\n",
       "  0.40819504857063293,\n",
       "  0.2962082028388977,\n",
       "  0.3769163489341736,\n",
       "  0.3428370952606201,\n",
       "  0.26879507303237915,\n",
       "  0.3029758036136627,\n",
       "  0.41139858961105347,\n",
       "  0.39835068583488464,\n",
       "  0.9894158244132996,\n",
       "  0.7160163521766663,\n",
       "  0.2852104604244232,\n",
       "  0.4473158121109009,\n",
       "  0.2376178354024887,\n",
       "  0.5074887275695801,\n",
       "  0.29352545738220215,\n",
       "  0.3910549283027649,\n",
       "  0.21324756741523743,\n",
       "  1.4623874425888062,\n",
       "  0.2613837718963623,\n",
       "  0.22399207949638367,\n",
       "  0.46733158826828003,\n",
       "  0.16547854244709015,\n",
       "  0.32540789246559143,\n",
       "  0.9832127094268799,\n",
       "  0.3123551905155182,\n",
       "  0.11334250867366791,\n",
       "  0.1774103343486786,\n",
       "  0.2599194049835205,\n",
       "  0.41537606716156006,\n",
       "  0.6679093837738037,\n",
       "  0.3685106635093689,\n",
       "  0.6644932627677917,\n",
       "  0.7121573686599731,\n",
       "  0.4598070979118347,\n",
       "  0.17278766632080078,\n",
       "  0.21403083205223083,\n",
       "  0.22295096516609192,\n",
       "  0.46434342861175537,\n",
       "  0.24635720252990723,\n",
       "  0.2687511444091797,\n",
       "  0.2706247568130493,\n",
       "  0.2327040284872055,\n",
       "  0.2821279466152191,\n",
       "  0.14575615525245667,\n",
       "  0.20226384699344635,\n",
       "  0.36623871326446533,\n",
       "  0.5819900631904602,\n",
       "  0.41128265857696533,\n",
       "  0.1995653510093689,\n",
       "  0.3799576759338379,\n",
       "  0.1387464702129364,\n",
       "  1.2036378383636475,\n",
       "  0.2717398703098297,\n",
       "  0.3974617123603821,\n",
       "  0.34871047735214233,\n",
       "  0.31290557980537415,\n",
       "  0.48655903339385986,\n",
       "  0.2512001693248749,\n",
       "  0.25932323932647705,\n",
       "  0.58316969871521,\n",
       "  0.5409117341041565,\n",
       "  0.33132949471473694,\n",
       "  0.38956645131111145,\n",
       "  0.24275356531143188,\n",
       "  0.3241978883743286,\n",
       "  0.16874904930591583,\n",
       "  0.2678878605365753,\n",
       "  0.3491620123386383,\n",
       "  0.3301612138748169,\n",
       "  0.6220121383666992,\n",
       "  0.47736984491348267,\n",
       "  0.23771780729293823,\n",
       "  0.17704682052135468,\n",
       "  0.3852265775203705,\n",
       "  0.20569097995758057,\n",
       "  0.3192821741104126,\n",
       "  0.86335289478302,\n",
       "  0.7505112886428833,\n",
       "  0.4662346839904785,\n",
       "  0.2508765757083893,\n",
       "  0.23914435505867004,\n",
       "  0.09916678071022034,\n",
       "  0.2629578113555908,\n",
       "  0.3069259822368622,\n",
       "  0.24312466382980347,\n",
       "  0.1631816178560257,\n",
       "  0.24289675056934357,\n",
       "  0.26061946153640747,\n",
       "  0.5242218375205994,\n",
       "  0.39261379837989807,\n",
       "  0.22783228754997253,\n",
       "  0.36232003569602966,\n",
       "  0.33693742752075195,\n",
       "  0.3919394016265869,\n",
       "  0.15119469165802002,\n",
       "  0.28225499391555786,\n",
       "  0.18441523611545563,\n",
       "  0.5929833650588989,\n",
       "  0.23734301328659058,\n",
       "  0.33951014280319214,\n",
       "  0.23051992058753967,\n",
       "  0.38434898853302,\n",
       "  0.13571669161319733,\n",
       "  0.08473798632621765,\n",
       "  0.250562459230423,\n",
       "  0.14271394908428192,\n",
       "  0.26689302921295166,\n",
       "  0.14073707163333893,\n",
       "  0.4017813205718994,\n",
       "  0.12759746611118317,\n",
       "  0.8782413005828857,\n",
       "  0.5654923915863037,\n",
       "  0.8473978638648987,\n",
       "  0.27439871430397034,\n",
       "  0.6698516607284546,\n",
       "  0.22078725695610046,\n",
       "  0.24330681562423706,\n",
       "  0.2538973093032837,\n",
       "  0.30644503235816956,\n",
       "  0.584578275680542,\n",
       "  0.061837852001190186,\n",
       "  0.3139733672142029,\n",
       "  0.1606265902519226,\n",
       "  0.3807440400123596,\n",
       "  0.15486788749694824,\n",
       "  0.3217220902442932,\n",
       "  0.32548415660858154,\n",
       "  0.3961021304130554,\n",
       "  0.4231352210044861,\n",
       "  0.1028890609741211,\n",
       "  0.15097539126873016,\n",
       "  0.149776428937912,\n",
       "  0.15760445594787598,\n",
       "  0.4041591286659241,\n",
       "  0.1382705122232437,\n",
       "  0.5357657670974731,\n",
       "  0.1825338900089264,\n",
       "  0.14644917845726013,\n",
       "  0.4283156394958496,\n",
       "  0.26333433389663696,\n",
       "  0.40222251415252686,\n",
       "  0.5362363457679749,\n",
       "  0.7603788375854492,\n",
       "  0.24503809213638306,\n",
       "  0.16781991720199585,\n",
       "  0.2136048674583435,\n",
       "  0.32443204522132874,\n",
       "  0.1623697578907013,\n",
       "  0.3809894621372223,\n",
       "  0.3059667646884918,\n",
       "  0.19474247097969055,\n",
       "  0.38697579503059387,\n",
       "  1.0496840476989746,\n",
       "  0.18335546553134918,\n",
       "  0.3513149321079254,\n",
       "  0.44707298278808594,\n",
       "  0.21996396780014038,\n",
       "  0.3696098327636719,\n",
       "  0.1411292850971222,\n",
       "  0.21697120368480682,\n",
       "  0.259473979473114,\n",
       "  0.31105828285217285,\n",
       "  0.5047588348388672,\n",
       "  0.2687934935092926,\n",
       "  0.4279223680496216,\n",
       "  0.5993564128875732,\n",
       "  0.9195491075515747,\n",
       "  0.2954464256763458,\n",
       "  0.3104124069213867,\n",
       "  0.16819339990615845,\n",
       "  0.8381448984146118,\n",
       "  0.2993287444114685,\n",
       "  0.29754728078842163,\n",
       "  0.27174824476242065,\n",
       "  0.3616918921470642,\n",
       "  0.3573904037475586,\n",
       "  0.34491291642189026,\n",
       "  0.29966065287590027,\n",
       "  0.3310798704624176,\n",
       "  0.402765154838562,\n",
       "  0.31793490052223206,\n",
       "  0.39928486943244934,\n",
       "  0.26955869793891907,\n",
       "  0.17669013142585754,\n",
       "  0.349871963262558,\n",
       "  0.19958755373954773,\n",
       "  0.19952262938022614,\n",
       "  0.2480284571647644,\n",
       "  0.30349433422088623,\n",
       "  0.21563296020030975,\n",
       "  0.16989925503730774,\n",
       "  0.7593632936477661,\n",
       "  1.0063374042510986,\n",
       "  0.3165608048439026,\n",
       "  0.37434279918670654,\n",
       "  0.2645319402217865,\n",
       "  0.276703804731369,\n",
       "  0.16610312461853027,\n",
       "  0.225784569978714,\n",
       "  0.4938940405845642,\n",
       "  0.38134002685546875,\n",
       "  0.27059638500213623,\n",
       "  0.4264194667339325,\n",
       "  0.4321795701980591,\n",
       "  0.14873923361301422,\n",
       "  0.25330060720443726,\n",
       "  0.16217488050460815,\n",
       "  0.13313962519168854,\n",
       "  0.6067177057266235,\n",
       "  0.20121200382709503,\n",
       "  0.2967040538787842,\n",
       "  0.232206791639328,\n",
       "  0.1668860763311386,\n",
       "  0.13370932638645172,\n",
       "  1.7236732244491577,\n",
       "  0.09681006520986557,\n",
       "  0.20202960073947906,\n",
       "  0.30005374550819397,\n",
       "  0.46579304337501526,\n",
       "  0.23146338760852814,\n",
       "  0.4472183585166931,\n",
       "  0.17619343101978302,\n",
       "  0.21576854586601257,\n",
       "  0.284993976354599,\n",
       "  0.1504010260105133,\n",
       "  0.4449928104877472,\n",
       "  0.11872080713510513,\n",
       "  0.23978497087955475,\n",
       "  0.41455158591270447,\n",
       "  0.18296103179454803,\n",
       "  0.4256155788898468,\n",
       "  0.27573007345199585,\n",
       "  0.38033953309059143,\n",
       "  0.906609296798706,\n",
       "  0.28309276700019836,\n",
       "  0.254140704870224,\n",
       "  0.25775834918022156,\n",
       "  0.2256506234407425,\n",
       "  0.45046040415763855,\n",
       "  0.2500435709953308,\n",
       "  0.18421176075935364,\n",
       "  0.15360695123672485,\n",
       "  0.17615723609924316,\n",
       "  0.37672626972198486,\n",
       "  0.39928096532821655,\n",
       "  0.35718077421188354,\n",
       "  0.3137328624725342,\n",
       "  0.2561258375644684,\n",
       "  0.26929545402526855,\n",
       "  0.21045543253421783,\n",
       "  0.24460949003696442,\n",
       "  0.3527909815311432,\n",
       "  0.13796772062778473,\n",
       "  0.2830072045326233,\n",
       "  0.11818257719278336,\n",
       "  0.20889818668365479,\n",
       "  0.42798876762390137,\n",
       "  0.1948392242193222,\n",
       "  0.08789968490600586,\n",
       "  2.718738555908203,\n",
       "  0.19627220928668976,\n",
       "  0.20581138134002686,\n",
       "  0.11413910239934921,\n",
       "  0.20883889496326447,\n",
       "  0.2703455984592438,\n",
       "  0.19826264679431915,\n",
       "  0.20232008397579193,\n",
       "  0.22619011998176575,\n",
       "  0.42601126432418823,\n",
       "  0.5502265691757202,\n",
       "  0.31530511379241943,\n",
       "  0.22701624035835266,\n",
       "  0.13702063262462616,\n",
       "  0.33550477027893066,\n",
       "  0.2799837589263916,\n",
       "  0.29459449648857117,\n",
       "  0.12963628768920898,\n",
       "  0.18307025730609894,\n",
       "  0.6088638305664062,\n",
       "  0.2539963126182556,\n",
       "  0.2558209300041199,\n",
       "  0.14204305410385132,\n",
       "  0.4006161391735077,\n",
       "  0.27391645312309265,\n",
       "  0.3344382047653198,\n",
       "  0.7070116400718689,\n",
       "  0.15009091794490814,\n",
       "  0.10053495317697525,\n",
       "  0.27304813265800476,\n",
       "  0.43353697657585144,\n",
       "  0.13200697302818298,\n",
       "  0.1441015899181366,\n",
       "  0.2084054797887802,\n",
       "  0.0569874607026577,\n",
       "  0.3942534327507019,\n",
       "  0.4931778907775879,\n",
       "  0.1830689013004303,\n",
       "  0.20516139268875122,\n",
       "  0.45947498083114624,\n",
       "  0.510148286819458,\n",
       "  0.31350868940353394,\n",
       "  0.16420409083366394,\n",
       "  0.23106764256954193,\n",
       "  0.6512518525123596,\n",
       "  0.354747474193573,\n",
       "  0.21212901175022125,\n",
       "  0.14098665118217468,\n",
       "  0.4407978653907776,\n",
       "  0.26286861300468445,\n",
       "  0.3476616442203522,\n",
       "  0.5146846175193787,\n",
       "  0.1789705604314804,\n",
       "  0.15266799926757812,\n",
       "  0.2860468626022339,\n",
       "  0.28760188817977905,\n",
       "  0.2293175756931305,\n",
       "  0.16904303431510925,\n",
       "  0.15203528106212616,\n",
       "  0.19796697795391083,\n",
       "  1.7396513223648071,\n",
       "  0.33211997151374817,\n",
       "  0.27597081661224365,\n",
       "  0.3455512225627899,\n",
       "  0.20474062860012054,\n",
       "  0.3030475974082947,\n",
       "  0.1231592446565628,\n",
       "  0.22226008772850037,\n",
       "  0.6168776750564575,\n",
       "  0.1965215504169464,\n",
       "  0.35944563150405884,\n",
       "  0.26469796895980835,\n",
       "  0.13195709884166718,\n",
       "  0.17978762090206146,\n",
       "  0.44373881816864014,\n",
       "  0.2736437916755676,\n",
       "  0.22936974465847015,\n",
       "  0.14720872044563293,\n",
       "  0.25910380482673645,\n",
       "  0.3483695089817047,\n",
       "  0.08339029550552368,\n",
       "  0.2590354382991791,\n",
       "  0.426560640335083,\n",
       "  0.17505645751953125,\n",
       "  0.6259737610816956,\n",
       "  0.19276292622089386,\n",
       "  0.3396154046058655,\n",
       "  0.1526741236448288,\n",
       "  0.2118200957775116,\n",
       "  0.15379281342029572,\n",
       "  0.26550254225730896,\n",
       "  0.10364837199449539,\n",
       "  0.41818737983703613,\n",
       "  0.13260158896446228,\n",
       "  0.15656651556491852,\n",
       "  0.1527019590139389,\n",
       "  0.0636785700917244,\n",
       "  0.06372810900211334,\n",
       "  0.530305802822113,\n",
       "  0.07594016194343567,\n",
       "  0.1713625192642212,\n",
       "  0.20458483695983887,\n",
       "  0.2380111962556839,\n",
       "  0.15813273191452026,\n",
       "  0.7867979407310486,\n",
       "  0.516542911529541,\n",
       "  0.10622825473546982,\n",
       "  0.13535566627979279,\n",
       "  0.3432982265949249,\n",
       "  0.3124043941497803,\n",
       "  0.12840008735656738,\n",
       "  0.11680974066257477,\n",
       "  0.04963628575205803,\n",
       "  0.15438541769981384,\n",
       "  0.03532831370830536,\n",
       "  0.2759743928909302,\n",
       "  0.08801913261413574,\n",
       "  0.11881789565086365,\n",
       "  0.10568084567785263,\n",
       "  0.16718342900276184,\n",
       "  0.20657549798488617,\n",
       "  0.16569295525550842,\n",
       "  0.09154395014047623,\n",
       "  0.21001559495925903,\n",
       "  0.5711634755134583,\n",
       "  0.3072032332420349,\n",
       "  0.14241285622119904,\n",
       "  0.35102587938308716,\n",
       "  0.10801110416650772,\n",
       "  0.3008882999420166,\n",
       "  0.03087589144706726,\n",
       "  0.12131477147340775,\n",
       "  0.12310734391212463,\n",
       "  0.5929566621780396,\n",
       "  0.12918207049369812,\n",
       "  0.23820455372333527,\n",
       "  0.04559670016169548,\n",
       "  0.4017631709575653,\n",
       "  0.012603200040757656,\n",
       "  0.15349794924259186,\n",
       "  0.35789012908935547,\n",
       "  0.22210681438446045,\n",
       "  0.2758448123931885,\n",
       "  1.1615114212036133,\n",
       "  0.16722016036510468,\n",
       "  0.19613580405712128,\n",
       "  0.2475488781929016,\n",
       "  0.016822384670376778,\n",
       "  0.9488357305526733,\n",
       "  0.24141576886177063,\n",
       "  0.10526583343744278,\n",
       "  0.030236253514885902,\n",
       "  0.08659057319164276,\n",
       "  0.16326364874839783,\n",
       "  0.19708596169948578,\n",
       "  0.37346822023391724,\n",
       "  0.17660267651081085,\n",
       "  0.17049214243888855,\n",
       "  0.23008599877357483,\n",
       "  0.18369045853614807,\n",
       "  0.1294628232717514,\n",
       "  0.18630525469779968,\n",
       "  0.18098895251750946,\n",
       "  0.38447850942611694,\n",
       "  0.25971320271492004,\n",
       "  0.13497798144817352,\n",
       "  0.32929176092147827,\n",
       "  0.22212108969688416,\n",
       "  0.08965185284614563,\n",
       "  0.19783459603786469,\n",
       "  0.0940742939710617,\n",
       "  0.24986112117767334,\n",
       "  0.18577392399311066,\n",
       "  0.42950907349586487,\n",
       "  0.2237604260444641,\n",
       "  0.204077810049057,\n",
       "  0.1263258457183838,\n",
       "  0.08382885903120041,\n",
       "  0.32580211758613586,\n",
       "  0.011652838438749313,\n",
       "  0.40465205907821655,\n",
       "  0.7717689871788025,\n",
       "  0.026970546692609787,\n",
       "  0.12345791608095169,\n",
       "  0.03749735653400421,\n",
       "  0.5079331398010254,\n",
       "  0.08290349692106247,\n",
       "  0.12851174175739288,\n",
       "  0.09198417514562607,\n",
       "  0.18169492483139038,\n",
       "  0.07122544199228287,\n",
       "  0.15541775524616241,\n",
       "  0.5257901549339294,\n",
       "  0.17888036370277405,\n",
       "  0.08230307698249817,\n",
       "  0.0742134377360344,\n",
       "  0.19442591071128845,\n",
       "  0.18824385106563568,\n",
       "  0.13517287373542786,\n",
       "  0.3704923987388611,\n",
       "  0.20152494311332703,\n",
       "  0.17870169878005981,\n",
       "  0.11661295592784882,\n",
       "  0.370355486869812,\n",
       "  0.056145988404750824,\n",
       "  0.2570120394229889,\n",
       "  0.021082716062664986,\n",
       "  0.05098086595535278,\n",
       "  0.03417569771409035],\n",
       " [0.77,\n",
       "  0.77,\n",
       "  0.77,\n",
       "  0.77,\n",
       "  0.77,\n",
       "  0.76,\n",
       "  0.79,\n",
       "  0.83,\n",
       "  0.83,\n",
       "  0.82,\n",
       "  0.88,\n",
       "  0.59,\n",
       "  0.82,\n",
       "  0.78,\n",
       "  0.81,\n",
       "  0.89,\n",
       "  0.89,\n",
       "  0.81,\n",
       "  0.85,\n",
       "  0.81,\n",
       "  0.84,\n",
       "  0.9,\n",
       "  0.86,\n",
       "  0.89,\n",
       "  0.88,\n",
       "  0.83,\n",
       "  0.86,\n",
       "  0.88,\n",
       "  0.82,\n",
       "  0.9,\n",
       "  0.85,\n",
       "  0.9,\n",
       "  0.87,\n",
       "  0.88,\n",
       "  0.82,\n",
       "  0.9,\n",
       "  0.9,\n",
       "  0.82,\n",
       "  0.9,\n",
       "  0.91,\n",
       "  0.9,\n",
       "  0.91,\n",
       "  0.93,\n",
       "  0.89,\n",
       "  0.9,\n",
       "  0.87,\n",
       "  0.91,\n",
       "  0.95,\n",
       "  0.81,\n",
       "  0.93])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.24526788294315338 | Val Accuracy=0.95: 100%|| 50/50 [03:27<00:00,  4.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.750299870967865,\n",
       "  0.7750956416130066,\n",
       "  0.6777176260948181,\n",
       "  0.744937539100647,\n",
       "  0.7255219221115112,\n",
       "  0.7526204586029053,\n",
       "  0.7503975033760071,\n",
       "  0.6845007538795471,\n",
       "  0.7701263427734375,\n",
       "  0.7293089628219604,\n",
       "  0.6695225238800049,\n",
       "  0.6923144459724426,\n",
       "  0.599391758441925,\n",
       "  0.6311220526695251,\n",
       "  0.8115617036819458,\n",
       "  0.5265838503837585,\n",
       "  0.6732302904129028,\n",
       "  0.5546417832374573,\n",
       "  0.626400887966156,\n",
       "  0.5129075050354004,\n",
       "  0.6075285077095032,\n",
       "  0.5520399212837219,\n",
       "  0.7383511662483215,\n",
       "  0.594693660736084,\n",
       "  0.7145194411277771,\n",
       "  0.6170514822006226,\n",
       "  0.7018414735794067,\n",
       "  0.637908399105072,\n",
       "  0.7786120176315308,\n",
       "  0.46498069167137146,\n",
       "  0.9260078072547913,\n",
       "  0.7250997424125671,\n",
       "  0.8283491134643555,\n",
       "  0.5325964093208313,\n",
       "  0.43606582283973694,\n",
       "  0.5661289691925049,\n",
       "  0.5587089657783508,\n",
       "  0.7459912896156311,\n",
       "  0.6792371273040771,\n",
       "  1.2567111253738403,\n",
       "  0.7070127129554749,\n",
       "  0.7839927673339844,\n",
       "  0.4762979745864868,\n",
       "  0.5648226141929626,\n",
       "  0.5050246119499207,\n",
       "  0.512738823890686,\n",
       "  0.6064925789833069,\n",
       "  0.6057626008987427,\n",
       "  0.5988214612007141,\n",
       "  0.7468657493591309,\n",
       "  0.7142589092254639,\n",
       "  0.6212375164031982,\n",
       "  0.5686185956001282,\n",
       "  0.4765135645866394,\n",
       "  0.6244708895683289,\n",
       "  0.5618535280227661,\n",
       "  0.5250657200813293,\n",
       "  0.6056604385375977,\n",
       "  0.6510579586029053,\n",
       "  0.6013022065162659,\n",
       "  0.45784831047058105,\n",
       "  0.48760780692100525,\n",
       "  0.4997289478778839,\n",
       "  0.6228871941566467,\n",
       "  0.5848920941352844,\n",
       "  0.26038768887519836,\n",
       "  1.2869277000427246,\n",
       "  0.5169756412506104,\n",
       "  0.6865314245223999,\n",
       "  0.7367540597915649,\n",
       "  0.5499733090400696,\n",
       "  0.4494290053844452,\n",
       "  0.9460565447807312,\n",
       "  0.5955759286880493,\n",
       "  0.4288131892681122,\n",
       "  0.553125262260437,\n",
       "  0.5778939723968506,\n",
       "  0.3852676451206207,\n",
       "  0.44633248448371887,\n",
       "  0.5266706347465515,\n",
       "  0.6514266133308411,\n",
       "  0.5640939474105835,\n",
       "  0.5483629107475281,\n",
       "  0.4353398382663727,\n",
       "  0.3746507465839386,\n",
       "  0.5957518219947815,\n",
       "  0.40635553002357483,\n",
       "  0.3813471496105194,\n",
       "  0.4386569559574127,\n",
       "  0.23622818291187286,\n",
       "  0.48098209500312805,\n",
       "  0.2680644094944,\n",
       "  0.44927090406417847,\n",
       "  0.4165101647377014,\n",
       "  0.8630990982055664,\n",
       "  0.43775108456611633,\n",
       "  0.36482691764831543,\n",
       "  0.4048526883125305,\n",
       "  0.6806104183197021,\n",
       "  0.14468100666999817,\n",
       "  0.5909861922264099,\n",
       "  0.9205363392829895,\n",
       "  0.3309456706047058,\n",
       "  0.7701139450073242,\n",
       "  0.7713253498077393,\n",
       "  0.3277871906757355,\n",
       "  0.6703433990478516,\n",
       "  0.46770164370536804,\n",
       "  0.3984863758087158,\n",
       "  0.22834016382694244,\n",
       "  0.5370385646820068,\n",
       "  0.45178183913230896,\n",
       "  0.4939970374107361,\n",
       "  0.48549044132232666,\n",
       "  0.34097927808761597,\n",
       "  0.5403568744659424,\n",
       "  0.36394184827804565,\n",
       "  0.329906165599823,\n",
       "  0.4809803068637848,\n",
       "  0.9253243207931519,\n",
       "  0.8773386478424072,\n",
       "  0.6206960678100586,\n",
       "  0.5819957852363586,\n",
       "  0.6224507093429565,\n",
       "  0.4328077435493469,\n",
       "  0.3515586853027344,\n",
       "  0.5677734613418579,\n",
       "  0.4150454103946686,\n",
       "  0.5788246393203735,\n",
       "  0.3878365755081177,\n",
       "  0.25075840950012207,\n",
       "  0.44773975014686584,\n",
       "  0.32974693179130554,\n",
       "  0.3050002157688141,\n",
       "  0.6916665434837341,\n",
       "  0.27084964513778687,\n",
       "  0.4333258271217346,\n",
       "  0.4163596034049988,\n",
       "  0.7592722177505493,\n",
       "  0.46977031230926514,\n",
       "  0.29075807332992554,\n",
       "  0.8110414147377014,\n",
       "  0.35028010606765747,\n",
       "  0.49258145689964294,\n",
       "  0.33550968766212463,\n",
       "  0.35146328806877136,\n",
       "  0.37349289655685425,\n",
       "  0.6296839118003845,\n",
       "  0.4378611445426941,\n",
       "  0.3377152383327484,\n",
       "  0.3883424401283264,\n",
       "  0.3011423945426941,\n",
       "  0.7287735939025879,\n",
       "  0.20577973127365112,\n",
       "  0.2479381114244461,\n",
       "  0.27585095167160034,\n",
       "  0.21819059550762177,\n",
       "  0.10646362602710724,\n",
       "  0.811050534248352,\n",
       "  0.4883641004562378,\n",
       "  0.32008978724479675,\n",
       "  0.37113460898399353,\n",
       "  0.1907331794500351,\n",
       "  0.8211553692817688,\n",
       "  0.4462842643260956,\n",
       "  0.8360751867294312,\n",
       "  0.23662272095680237,\n",
       "  0.4059359133243561,\n",
       "  0.5863537788391113,\n",
       "  0.6932860016822815,\n",
       "  0.2639707028865814,\n",
       "  0.4577307105064392,\n",
       "  0.20252037048339844,\n",
       "  0.27959781885147095,\n",
       "  0.3159494698047638,\n",
       "  0.21556290984153748,\n",
       "  0.4963011145591736,\n",
       "  0.3875097930431366,\n",
       "  0.47511932253837585,\n",
       "  0.4176211655139923,\n",
       "  0.5610274076461792,\n",
       "  0.5739092230796814,\n",
       "  0.21158845722675323,\n",
       "  0.13722215592861176,\n",
       "  0.3488112688064575,\n",
       "  0.3818802535533905,\n",
       "  0.5460189580917358,\n",
       "  0.3264015316963196,\n",
       "  0.24367418885231018,\n",
       "  0.8118148446083069,\n",
       "  0.2522018849849701,\n",
       "  0.6640657186508179,\n",
       "  0.4279622733592987,\n",
       "  0.3933708965778351,\n",
       "  0.34999576210975647,\n",
       "  0.23571886122226715,\n",
       "  0.16918368637561798,\n",
       "  0.43440374732017517,\n",
       "  0.10786444693803787,\n",
       "  0.49681687355041504,\n",
       "  0.3060324788093567,\n",
       "  0.5188741087913513,\n",
       "  0.2739998698234558,\n",
       "  0.584113359451294,\n",
       "  0.2900795042514801,\n",
       "  0.627220094203949,\n",
       "  0.3876873850822449,\n",
       "  0.2853180766105652,\n",
       "  0.3175942897796631,\n",
       "  1.0380570888519287,\n",
       "  0.25150373578071594,\n",
       "  0.3083609342575073,\n",
       "  0.1260516196489334,\n",
       "  0.11612243205308914,\n",
       "  0.22764739394187927,\n",
       "  0.3057471513748169,\n",
       "  0.27857863903045654,\n",
       "  0.3504936099052429,\n",
       "  0.24930737912654877,\n",
       "  0.6750640273094177,\n",
       "  0.3675512671470642,\n",
       "  0.21311424672603607,\n",
       "  0.5476605296134949,\n",
       "  0.38639283180236816,\n",
       "  0.19378995895385742,\n",
       "  0.2624000012874603,\n",
       "  0.26971715688705444,\n",
       "  0.23671428859233856,\n",
       "  0.5854195952415466,\n",
       "  1.0919485092163086,\n",
       "  0.49513736367225647,\n",
       "  0.406271755695343,\n",
       "  0.5139104127883911,\n",
       "  0.18728530406951904,\n",
       "  0.6594538688659668,\n",
       "  0.19480393826961517,\n",
       "  0.25541970133781433,\n",
       "  0.2449568808078766,\n",
       "  0.0659688338637352,\n",
       "  0.45694398880004883,\n",
       "  0.2758921682834625,\n",
       "  0.5681687593460083,\n",
       "  0.4140987694263458,\n",
       "  0.20540036261081696,\n",
       "  0.3329632580280304,\n",
       "  0.22738692164421082,\n",
       "  0.4130086600780487,\n",
       "  0.4112999141216278,\n",
       "  0.25105950236320496,\n",
       "  0.6008307337760925,\n",
       "  0.3018355071544647,\n",
       "  0.2328929752111435,\n",
       "  0.16117392480373383,\n",
       "  0.3943925201892853,\n",
       "  0.2087537944316864,\n",
       "  0.6277376413345337,\n",
       "  0.607459545135498,\n",
       "  0.42816129326820374,\n",
       "  0.7895187139511108,\n",
       "  0.292731374502182,\n",
       "  0.10869603604078293,\n",
       "  0.30246487259864807,\n",
       "  0.11603490263223648,\n",
       "  0.1457103043794632,\n",
       "  0.7583377361297607,\n",
       "  0.6174312233924866,\n",
       "  0.39214396476745605,\n",
       "  0.3384757936000824,\n",
       "  0.5364941358566284,\n",
       "  0.20843790471553802,\n",
       "  0.21926862001419067,\n",
       "  0.15327833592891693,\n",
       "  0.15418441593647003,\n",
       "  0.20261803269386292,\n",
       "  0.5189215540885925,\n",
       "  0.27752685546875,\n",
       "  1.028517723083496,\n",
       "  0.3701188266277313,\n",
       "  0.46254971623420715,\n",
       "  0.6630167961120605,\n",
       "  0.10685355216264725,\n",
       "  0.3695926070213318,\n",
       "  0.18592502176761627,\n",
       "  0.25435781478881836,\n",
       "  0.17955341935157776,\n",
       "  0.26521262526512146,\n",
       "  0.1745852380990982,\n",
       "  0.5928656458854675,\n",
       "  0.07618026435375214,\n",
       "  0.16578923165798187,\n",
       "  0.17692485451698303,\n",
       "  0.2139330357313156,\n",
       "  0.2866295278072357,\n",
       "  0.33088219165802,\n",
       "  0.11258135735988617,\n",
       "  0.07615604996681213,\n",
       "  0.21768145263195038,\n",
       "  0.2185768187046051,\n",
       "  0.6049340963363647,\n",
       "  0.17134155333042145,\n",
       "  0.14073540270328522,\n",
       "  0.09680784493684769,\n",
       "  0.2896150052547455,\n",
       "  0.3763255774974823,\n",
       "  0.29043200612068176,\n",
       "  0.2512032687664032,\n",
       "  0.13448578119277954,\n",
       "  0.07809428125619888,\n",
       "  0.1121559739112854,\n",
       "  0.37147367000579834,\n",
       "  0.15306217968463898,\n",
       "  0.258608341217041,\n",
       "  0.050070494413375854,\n",
       "  0.08547257632017136,\n",
       "  0.7721270322799683,\n",
       "  0.04756749048829079,\n",
       "  0.4291962683200836,\n",
       "  0.5401346683502197,\n",
       "  0.1614585667848587,\n",
       "  1.1071711778640747,\n",
       "  0.3700558543205261,\n",
       "  1.2897515296936035,\n",
       "  0.36463385820388794,\n",
       "  0.3081043064594269,\n",
       "  0.3990156352519989,\n",
       "  0.14893370866775513,\n",
       "  0.11636084318161011,\n",
       "  0.08180565387010574,\n",
       "  2.6285879611968994,\n",
       "  0.6894278526306152,\n",
       "  0.5721820592880249,\n",
       "  0.18889474868774414,\n",
       "  0.4442133605480194,\n",
       "  0.913602352142334,\n",
       "  0.2684731185436249,\n",
       "  0.5813177227973938,\n",
       "  0.42160117626190186,\n",
       "  0.4002892076969147,\n",
       "  0.46342599391937256,\n",
       "  0.4015841484069824,\n",
       "  0.2918238639831543,\n",
       "  0.5092703700065613,\n",
       "  0.394671231508255,\n",
       "  0.42324432730674744,\n",
       "  0.4125310182571411,\n",
       "  0.2498200237751007,\n",
       "  0.5149679780006409,\n",
       "  0.31741949915885925,\n",
       "  0.3575620949268341,\n",
       "  0.2971334457397461,\n",
       "  0.2879500091075897,\n",
       "  0.3210331201553345,\n",
       "  0.3613205552101135,\n",
       "  0.36412402987480164,\n",
       "  0.364526629447937,\n",
       "  0.32233211398124695,\n",
       "  0.1937483847141266,\n",
       "  0.30706480145454407,\n",
       "  0.2803155183792114,\n",
       "  0.15439081192016602,\n",
       "  0.2975618243217468,\n",
       "  0.3342970907688141,\n",
       "  0.2337733507156372,\n",
       "  0.1538105309009552,\n",
       "  0.3104458749294281,\n",
       "  0.2974068820476532,\n",
       "  0.11453578621149063,\n",
       "  0.36256641149520874,\n",
       "  0.15268740057945251,\n",
       "  0.4000866711139679,\n",
       "  0.09721846878528595,\n",
       "  0.07711492478847504,\n",
       "  0.46403828263282776,\n",
       "  0.41249603033065796,\n",
       "  0.2856147587299347,\n",
       "  0.3694109320640564,\n",
       "  0.21449902653694153,\n",
       "  0.07251323014497757,\n",
       "  0.5486764907836914,\n",
       "  0.5107402205467224,\n",
       "  0.1468302458524704,\n",
       "  0.12840725481510162,\n",
       "  0.3620692193508148,\n",
       "  0.3086344599723816,\n",
       "  0.3798084259033203,\n",
       "  0.31264328956604004,\n",
       "  0.18318341672420502,\n",
       "  0.23487716913223267,\n",
       "  0.43731561303138733,\n",
       "  0.658625602722168,\n",
       "  0.4494808316230774,\n",
       "  0.26840925216674805,\n",
       "  0.08143162727355957,\n",
       "  0.28181663155555725,\n",
       "  0.12302654981613159,\n",
       "  0.32758206129074097,\n",
       "  0.08133354783058167,\n",
       "  0.4497176706790924,\n",
       "  0.29335731267929077,\n",
       "  0.2422882318496704,\n",
       "  0.24016490578651428,\n",
       "  0.4024442136287689,\n",
       "  0.05987463891506195,\n",
       "  0.3769911229610443,\n",
       "  0.3025621473789215,\n",
       "  0.05920933187007904,\n",
       "  0.07311888784170151,\n",
       "  0.12929867208003998,\n",
       "  0.2545492947101593,\n",
       "  0.07614859193563461,\n",
       "  0.09076879918575287,\n",
       "  0.4066871702671051,\n",
       "  0.065949946641922,\n",
       "  0.2489534467458725,\n",
       "  0.07667313516139984,\n",
       "  0.1967899352312088,\n",
       "  0.1783445179462433,\n",
       "  0.283797025680542,\n",
       "  0.2773208022117615,\n",
       "  0.13969814777374268,\n",
       "  0.0765315368771553,\n",
       "  0.2690296173095703,\n",
       "  0.25185227394104004,\n",
       "  0.1284732073545456,\n",
       "  0.08851852267980576,\n",
       "  0.13936291635036469,\n",
       "  0.39778926968574524,\n",
       "  0.16467946767807007,\n",
       "  0.21369656920433044,\n",
       "  0.2510753273963928,\n",
       "  0.07221021503210068,\n",
       "  0.018559226766228676,\n",
       "  0.2981431484222412,\n",
       "  0.03014940395951271,\n",
       "  0.10178516060113907,\n",
       "  0.17250199615955353,\n",
       "  0.48784059286117554,\n",
       "  0.19742104411125183,\n",
       "  0.298692911863327,\n",
       "  0.054000165313482285,\n",
       "  0.25789546966552734,\n",
       "  0.06976447999477386,\n",
       "  0.4412006139755249,\n",
       "  0.030291486531496048,\n",
       "  0.07205455750226974,\n",
       "  0.03185560181736946,\n",
       "  0.47164595127105713,\n",
       "  0.2799834609031677,\n",
       "  0.1872723549604416,\n",
       "  0.42807281017303467,\n",
       "  0.5040422081947327,\n",
       "  0.21825052797794342,\n",
       "  0.2479129582643509,\n",
       "  0.1373257040977478,\n",
       "  0.5723458528518677,\n",
       "  0.12390592694282532,\n",
       "  0.2073613852262497,\n",
       "  0.05894005671143532,\n",
       "  0.1187533512711525,\n",
       "  0.1219271868467331,\n",
       "  0.15539534389972687,\n",
       "  0.07484752684831619,\n",
       "  0.040776584297418594,\n",
       "  0.1971597522497177,\n",
       "  0.7838719487190247,\n",
       "  0.10348642617464066,\n",
       "  0.2448681890964508,\n",
       "  0.2929140627384186,\n",
       "  0.2499583214521408,\n",
       "  0.29299265146255493,\n",
       "  0.021833309903740883,\n",
       "  0.18875981867313385,\n",
       "  0.15779685974121094,\n",
       "  0.3702801764011383,\n",
       "  0.21665318310260773,\n",
       "  0.23210617899894714,\n",
       "  0.3484838604927063,\n",
       "  0.25739163160324097,\n",
       "  0.7969112992286682,\n",
       "  0.11343705654144287,\n",
       "  0.0875953659415245,\n",
       "  0.16951359808444977,\n",
       "  0.08495708554983139,\n",
       "  0.20116421580314636,\n",
       "  0.3217971920967102,\n",
       "  0.41847044229507446,\n",
       "  0.09462948888540268,\n",
       "  0.20323842763900757,\n",
       "  0.9568599462509155,\n",
       "  0.08627140522003174,\n",
       "  0.14065933227539062,\n",
       "  0.7922027707099915,\n",
       "  0.15013903379440308,\n",
       "  0.132684126496315,\n",
       "  0.19151829183101654,\n",
       "  0.038631830364465714,\n",
       "  0.5258713364601135,\n",
       "  0.2822326719760895,\n",
       "  0.3116118907928467,\n",
       "  0.0746178925037384,\n",
       "  0.17258310317993164,\n",
       "  0.42812737822532654,\n",
       "  0.15405195951461792,\n",
       "  0.2094273865222931,\n",
       "  0.11235375702381134,\n",
       "  0.7211674451828003,\n",
       "  0.09555310755968094,\n",
       "  0.12678781151771545,\n",
       "  0.8819971680641174,\n",
       "  0.07002054154872894,\n",
       "  0.12260504066944122,\n",
       "  0.3885830044746399,\n",
       "  0.32039862871170044,\n",
       "  0.2509239614009857,\n",
       "  0.12102533131837845,\n",
       "  0.07243652641773224,\n",
       "  0.2852242887020111,\n",
       "  0.11481992900371552,\n",
       "  0.2513820230960846,\n",
       "  0.19477850198745728,\n",
       "  0.0709325522184372,\n",
       "  0.08894642442464828,\n",
       "  0.21332666277885437,\n",
       "  0.37009742856025696,\n",
       "  0.09320598095655441,\n",
       "  0.2611933946609497,\n",
       "  0.12780794501304626,\n",
       "  0.28139835596084595,\n",
       "  0.08778119087219238,\n",
       "  0.41954585909843445,\n",
       "  0.18195608258247375,\n",
       "  0.048309557139873505,\n",
       "  0.040436018258333206,\n",
       "  0.21663303673267365,\n",
       "  0.8493241667747498,\n",
       "  0.13624010980129242,\n",
       "  0.2702176570892334,\n",
       "  0.06416825205087662,\n",
       "  0.23372700810432434,\n",
       "  0.004987375810742378,\n",
       "  0.030833160504698753,\n",
       "  0.09068455547094345,\n",
       "  0.24536915123462677,\n",
       "  0.020421823486685753,\n",
       "  0.3124804198741913,\n",
       "  0.24493162333965302,\n",
       "  0.1544611006975174,\n",
       "  0.08993617445230484,\n",
       "  0.14039498567581177,\n",
       "  0.5041075348854065,\n",
       "  0.2708764672279358,\n",
       "  0.05324450880289078,\n",
       "  0.2012757658958435,\n",
       "  0.3511258065700531,\n",
       "  0.10923226177692413,\n",
       "  0.08564389497041702,\n",
       "  0.0766272321343422,\n",
       "  0.07744912803173065,\n",
       "  0.06061297655105591,\n",
       "  0.2542549669742584,\n",
       "  0.7614567279815674,\n",
       "  0.7057794332504272,\n",
       "  0.15190185606479645,\n",
       "  0.07561459392309189,\n",
       "  0.05012624338269234,\n",
       "  0.1863114982843399,\n",
       "  0.5401795506477356,\n",
       "  0.19802270829677582,\n",
       "  0.048395685851573944,\n",
       "  0.02469201758503914,\n",
       "  0.09899786859750748,\n",
       "  0.21264204382896423,\n",
       "  0.4846765995025635,\n",
       "  0.2693825960159302,\n",
       "  0.06520412862300873,\n",
       "  0.24471424520015717,\n",
       "  0.23519325256347656,\n",
       "  0.03002154268324375,\n",
       "  0.1157391294836998,\n",
       "  0.06401212513446808,\n",
       "  0.14577823877334595,\n",
       "  0.1941223293542862,\n",
       "  0.05656559020280838,\n",
       "  0.049372706562280655,\n",
       "  0.24304130673408508,\n",
       "  0.48838937282562256,\n",
       "  0.03604503720998764,\n",
       "  0.20475733280181885,\n",
       "  0.014769383706152439,\n",
       "  0.2024906873703003,\n",
       "  0.0705140084028244,\n",
       "  1.1314423084259033,\n",
       "  0.06341960281133652,\n",
       "  0.12824197113513947,\n",
       "  0.24872396886348724,\n",
       "  0.10232896357774734,\n",
       "  0.6775304079055786,\n",
       "  0.0454542376101017,\n",
       "  0.431588351726532,\n",
       "  0.3109434247016907,\n",
       "  0.7851608991622925,\n",
       "  0.06503617018461227,\n",
       "  0.35302355885505676,\n",
       "  0.10547709465026855,\n",
       "  0.6047532558441162,\n",
       "  0.05037825182080269,\n",
       "  0.8513604998588562,\n",
       "  0.23653490841388702,\n",
       "  0.07715382426977158,\n",
       "  0.5494931936264038,\n",
       "  0.17585794627666473,\n",
       "  0.3140277564525604,\n",
       "  0.1264527440071106,\n",
       "  0.22622862458229065,\n",
       "  0.30430278182029724,\n",
       "  0.19395656883716583,\n",
       "  0.2464977651834488,\n",
       "  0.31265395879745483,\n",
       "  0.19006380438804626,\n",
       "  0.19981321692466736,\n",
       "  0.24429859220981598,\n",
       "  0.1676245480775833,\n",
       "  0.36699751019477844,\n",
       "  0.29657816886901855,\n",
       "  0.3037286102771759,\n",
       "  0.6535382866859436,\n",
       "  0.15879538655281067,\n",
       "  0.31855618953704834,\n",
       "  0.220009908080101,\n",
       "  0.0706791877746582,\n",
       "  0.2693125903606415,\n",
       "  0.14367473125457764,\n",
       "  0.188516765832901,\n",
       "  0.14466290175914764,\n",
       "  0.20378707349300385,\n",
       "  0.24863582849502563,\n",
       "  0.374429315328598,\n",
       "  0.19172517955303192,\n",
       "  0.5995973348617554,\n",
       "  0.69442218542099,\n",
       "  0.2658836245536804,\n",
       "  0.05321576073765755,\n",
       "  0.12221173942089081,\n",
       "  0.15633521974086761,\n",
       "  0.10187286883592606,\n",
       "  0.06233472377061844,\n",
       "  0.29970139265060425,\n",
       "  0.06485855579376221,\n",
       "  0.0499836727976799,\n",
       "  0.23545469343662262,\n",
       "  0.2252650260925293,\n",
       "  0.06385393440723419,\n",
       "  0.05697183683514595,\n",
       "  0.034210868179798126,\n",
       "  0.07446085661649704,\n",
       "  0.6187190413475037,\n",
       "  0.46652019023895264,\n",
       "  0.47394078969955444,\n",
       "  0.04680538550019264,\n",
       "  0.031140953302383423,\n",
       "  0.01930137351155281,\n",
       "  0.18823522329330444,\n",
       "  0.18183475732803345,\n",
       "  0.06590571254491806,\n",
       "  0.00791039876639843,\n",
       "  0.21958811581134796,\n",
       "  0.20197694003582,\n",
       "  0.6331274509429932,\n",
       "  0.21210214495658875,\n",
       "  0.10027481615543365,\n",
       "  0.03209478035569191,\n",
       "  0.08023804426193237,\n",
       "  0.20634156465530396,\n",
       "  0.21770353615283966,\n",
       "  0.2583538591861725,\n",
       "  0.13331954181194305,\n",
       "  0.3017732799053192,\n",
       "  0.22763444483280182,\n",
       "  0.030290357768535614,\n",
       "  0.21767309308052063,\n",
       "  0.19944679737091064,\n",
       "  0.18229053914546967,\n",
       "  0.2683604061603546,\n",
       "  0.062324587255716324,\n",
       "  0.4709096848964691,\n",
       "  0.038747821003198624,\n",
       "  0.07418674230575562,\n",
       "  0.27131327986717224,\n",
       "  0.18619412183761597,\n",
       "  0.03480207920074463,\n",
       "  0.1415090411901474,\n",
       "  0.3930773138999939,\n",
       "  0.10048670321702957,\n",
       "  0.2318604737520218,\n",
       "  0.1404505968093872,\n",
       "  0.011897985823452473,\n",
       "  0.3023260831832886,\n",
       "  0.13393953442573547,\n",
       "  0.044546712189912796,\n",
       "  0.36410871148109436,\n",
       "  0.1867872029542923,\n",
       "  0.08893221616744995,\n",
       "  0.15638071298599243,\n",
       "  0.015179086476564407,\n",
       "  0.042669422924518585,\n",
       "  0.1400781273841858,\n",
       "  0.04284676909446716,\n",
       "  0.21897023916244507,\n",
       "  0.17306706309318542,\n",
       "  0.11444650590419769,\n",
       "  0.09634572267532349,\n",
       "  0.08999815583229065,\n",
       "  0.07592794299125671,\n",
       "  0.021453142166137695,\n",
       "  0.2344188541173935,\n",
       "  0.8028550744056702,\n",
       "  0.23123788833618164,\n",
       "  0.059911247342824936,\n",
       "  0.011955467984080315,\n",
       "  0.08014515787363052,\n",
       "  0.09875017404556274,\n",
       "  0.020181210711598396,\n",
       "  0.024316590279340744,\n",
       "  0.0032368390820920467,\n",
       "  0.40142738819122314,\n",
       "  0.18331007659435272,\n",
       "  0.3678833842277527,\n",
       "  0.200715571641922,\n",
       "  0.019911685958504677,\n",
       "  0.07132092863321304,\n",
       "  0.16036950051784515,\n",
       "  0.020667174831032753,\n",
       "  0.1017996072769165,\n",
       "  0.008374080061912537,\n",
       "  0.009062077850103378,\n",
       "  0.10559899359941483,\n",
       "  0.22311361134052277,\n",
       "  0.029323572292923927,\n",
       "  0.49722346663475037,\n",
       "  0.39552173018455505,\n",
       "  0.18067333102226257,\n",
       "  0.008346952497959137,\n",
       "  0.11393991857767105,\n",
       "  0.15456946194171906,\n",
       "  0.16901277005672455,\n",
       "  0.1427316516637802,\n",
       "  0.07115292549133301,\n",
       "  0.15231887996196747,\n",
       "  0.021913178265094757,\n",
       "  0.010226011276245117,\n",
       "  0.026793787255883217,\n",
       "  0.20966540277004242,\n",
       "  0.19068284332752228,\n",
       "  0.25080132484436035,\n",
       "  0.06323022395372391,\n",
       "  0.2691308557987213,\n",
       "  0.36901599168777466,\n",
       "  0.08541238307952881,\n",
       "  0.1192256361246109,\n",
       "  0.04402228444814682,\n",
       "  0.16744638979434967,\n",
       "  0.005978594068437815,\n",
       "  0.07291603088378906,\n",
       "  0.13147054612636566,\n",
       "  0.1344844251871109,\n",
       "  0.013849319890141487,\n",
       "  0.00696181133389473,\n",
       "  0.02657099813222885,\n",
       "  0.17055656015872955,\n",
       "  0.012187233194708824,\n",
       "  0.0582076795399189,\n",
       "  0.041167471557855606,\n",
       "  0.5951531529426575,\n",
       "  0.06796860694885254,\n",
       "  0.07508211582899094,\n",
       "  0.10918643325567245,\n",
       "  0.030241165310144424,\n",
       "  0.6266120076179504,\n",
       "  0.012422828003764153,\n",
       "  0.05917669087648392,\n",
       "  0.16175566613674164,\n",
       "  0.1325094848871231,\n",
       "  0.11960603296756744,\n",
       "  0.03335164487361908,\n",
       "  0.04247724264860153,\n",
       "  0.013216487132012844,\n",
       "  0.19235432147979736,\n",
       "  0.11316267400979996,\n",
       "  0.46589380502700806,\n",
       "  0.09625222533941269,\n",
       "  0.030623313039541245,\n",
       "  1.143781304359436,\n",
       "  0.06314556300640106,\n",
       "  0.6034246683120728,\n",
       "  0.05559969320893288,\n",
       "  0.28245487809181213,\n",
       "  0.4740753173828125,\n",
       "  0.2941839396953583,\n",
       "  0.40584036707878113,\n",
       "  0.22647766768932343,\n",
       "  0.08587399870157242,\n",
       "  0.2751222252845764,\n",
       "  0.30231359601020813,\n",
       "  0.19783243536949158,\n",
       "  0.07266268134117126,\n",
       "  0.5430317521095276,\n",
       "  0.2496931254863739,\n",
       "  0.13612134754657745,\n",
       "  0.22362709045410156,\n",
       "  0.30679264664649963,\n",
       "  0.6220664978027344,\n",
       "  0.1119164228439331,\n",
       "  0.2547290027141571,\n",
       "  0.09294062852859497,\n",
       "  0.13733592629432678,\n",
       "  0.5124529600143433,\n",
       "  0.20060165226459503,\n",
       "  0.09046164155006409,\n",
       "  1.8544085025787354,\n",
       "  0.045241743326187134,\n",
       "  0.013643823564052582,\n",
       "  0.08497357368469238,\n",
       "  0.0162883959710598,\n",
       "  0.5252506136894226,\n",
       "  0.016103599220514297,\n",
       "  0.20800356566905975,\n",
       "  0.10526707023382187,\n",
       "  0.10376250743865967,\n",
       "  0.0932517871260643,\n",
       "  0.09670304507017136,\n",
       "  0.14649613201618195,\n",
       "  0.03867865726351738,\n",
       "  0.07821904122829437,\n",
       "  0.030974341556429863,\n",
       "  0.19474345445632935,\n",
       "  0.027222897857427597,\n",
       "  0.12681891024112701,\n",
       "  0.2485603392124176,\n",
       "  0.052026137709617615,\n",
       "  0.6574554443359375,\n",
       "  0.026719115674495697,\n",
       "  0.477765291929245,\n",
       "  0.13030853867530823,\n",
       "  0.1715291440486908,\n",
       "  0.21188004314899445,\n",
       "  0.023719996213912964,\n",
       "  0.017623931169509888,\n",
       "  0.08492660522460938,\n",
       "  0.35395053029060364,\n",
       "  0.04401342198252678,\n",
       "  0.34139686822891235,\n",
       "  0.7736639380455017,\n",
       "  0.1725790649652481,\n",
       "  0.21603144705295563,\n",
       "  0.12515538930892944,\n",
       "  0.21558114886283875,\n",
       "  0.04890800639986992,\n",
       "  0.19878935813903809,\n",
       "  0.08616840094327927,\n",
       "  0.14873501658439636,\n",
       "  0.23602569103240967,\n",
       "  0.0487934872508049,\n",
       "  0.022547215223312378,\n",
       "  0.02909579873085022,\n",
       "  0.053732749074697495,\n",
       "  0.10763655602931976,\n",
       "  0.2496834099292755,\n",
       "  0.962338387966156,\n",
       "  0.13969074189662933,\n",
       "  0.04941190034151077,\n",
       "  0.07559742033481598,\n",
       "  0.1139732077717781,\n",
       "  0.06713249534368515,\n",
       "  0.2275344431400299,\n",
       "  0.18443429470062256,\n",
       "  0.04857568070292473,\n",
       "  0.20913353562355042,\n",
       "  0.0898846983909607,\n",
       "  0.13088157773017883,\n",
       "  0.17653222382068634,\n",
       "  0.06428246945142746,\n",
       "  0.24526788294315338,\n",
       "  0.029210355132818222,\n",
       "  0.021950064226984978,\n",
       "  0.33733028173446655,\n",
       "  0.2221015989780426,\n",
       "  0.2438330054283142,\n",
       "  0.0695645734667778,\n",
       "  0.9221899509429932,\n",
       "  0.2182021141052246,\n",
       "  0.3681061863899231,\n",
       "  0.34854692220687866,\n",
       "  0.12709617614746094,\n",
       "  0.09383360296487808,\n",
       "  0.04370306432247162,\n",
       "  0.01282544806599617,\n",
       "  0.026241982355713844,\n",
       "  0.1498694270849228,\n",
       "  0.053177349269390106,\n",
       "  0.03803519159555435],\n",
       " [0.7,\n",
       "  0.53,\n",
       "  0.71,\n",
       "  0.82,\n",
       "  0.77,\n",
       "  0.76,\n",
       "  0.86,\n",
       "  0.74,\n",
       "  0.83,\n",
       "  0.84,\n",
       "  0.78,\n",
       "  0.83,\n",
       "  0.9,\n",
       "  0.92,\n",
       "  0.94,\n",
       "  0.8,\n",
       "  0.64,\n",
       "  0.9,\n",
       "  0.88,\n",
       "  0.9,\n",
       "  0.59,\n",
       "  0.85,\n",
       "  0.91,\n",
       "  0.95,\n",
       "  0.94,\n",
       "  0.88,\n",
       "  0.94,\n",
       "  0.92,\n",
       "  0.95,\n",
       "  0.93,\n",
       "  0.91,\n",
       "  0.94,\n",
       "  0.88,\n",
       "  0.96,\n",
       "  0.93,\n",
       "  0.89,\n",
       "  0.95,\n",
       "  0.94,\n",
       "  0.95,\n",
       "  0.98,\n",
       "  0.92,\n",
       "  0.96,\n",
       "  0.97,\n",
       "  0.93,\n",
       "  0.86,\n",
       "  0.92,\n",
       "  0.97,\n",
       "  0.98,\n",
       "  0.95,\n",
       "  0.95])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train(train_data, oversample_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.45734965801239014 | Val Accuracy=1.0: 100%|| 50/50 [03:19<00:00,  3.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7090036869049072,\n",
       "  0.7152204513549805,\n",
       "  0.7157958149909973,\n",
       "  0.6982258558273315,\n",
       "  0.6748698353767395,\n",
       "  0.6964111924171448,\n",
       "  0.6617436408996582,\n",
       "  0.7180818915367126,\n",
       "  0.6953784823417664,\n",
       "  0.6406789422035217,\n",
       "  0.6210229396820068,\n",
       "  0.6950288414955139,\n",
       "  0.5819463133811951,\n",
       "  0.5076451897621155,\n",
       "  0.6478569507598877,\n",
       "  0.5704215168952942,\n",
       "  0.43701741099357605,\n",
       "  0.4971492886543274,\n",
       "  0.38572749495506287,\n",
       "  0.4349347651004791,\n",
       "  0.8031170964241028,\n",
       "  1.1639970541000366,\n",
       "  0.6568372845649719,\n",
       "  0.5631312727928162,\n",
       "  0.5447168350219727,\n",
       "  0.5871116518974304,\n",
       "  0.5890299677848816,\n",
       "  0.3608038127422333,\n",
       "  0.3576294183731079,\n",
       "  0.42346641421318054,\n",
       "  0.4311385750770569,\n",
       "  0.48179712891578674,\n",
       "  0.6508729457855225,\n",
       "  0.3970390260219574,\n",
       "  0.5332486629486084,\n",
       "  0.8880676627159119,\n",
       "  0.30363941192626953,\n",
       "  0.5143499970436096,\n",
       "  0.28199416399002075,\n",
       "  0.2519696354866028,\n",
       "  0.5213218331336975,\n",
       "  0.45842650532722473,\n",
       "  0.40298694372177124,\n",
       "  0.19821491837501526,\n",
       "  0.17408360540866852,\n",
       "  0.10467745363712311,\n",
       "  0.11577823758125305,\n",
       "  0.1136348769068718,\n",
       "  0.49477654695510864,\n",
       "  0.08047349750995636,\n",
       "  0.37558794021606445,\n",
       "  0.4463755190372467,\n",
       "  0.21846814453601837,\n",
       "  0.16667456924915314,\n",
       "  0.23693716526031494,\n",
       "  0.027166103944182396,\n",
       "  0.04388492554426193,\n",
       "  0.04185132682323456,\n",
       "  0.019923515617847443,\n",
       "  0.17900387942790985,\n",
       "  0.41248664259910583,\n",
       "  0.3621287941932678,\n",
       "  0.538288414478302,\n",
       "  0.023945800960063934,\n",
       "  0.439748078584671,\n",
       "  0.07481492310762405,\n",
       "  0.009860231541097164,\n",
       "  0.06887618452310562,\n",
       "  0.3345804214477539,\n",
       "  0.10840753465890884,\n",
       "  1.6658098697662354,\n",
       "  0.03254178911447525,\n",
       "  0.26269978284835815,\n",
       "  0.022415779531002045,\n",
       "  0.01613001525402069,\n",
       "  0.21878936886787415,\n",
       "  0.060304999351501465,\n",
       "  0.037446312606334686,\n",
       "  0.44520044326782227,\n",
       "  0.4579145312309265,\n",
       "  0.61684250831604,\n",
       "  0.024751920253038406,\n",
       "  0.7894684076309204,\n",
       "  0.5923788547515869,\n",
       "  0.13754528760910034,\n",
       "  0.11157988011837006,\n",
       "  0.16404011845588684,\n",
       "  0.19085213541984558,\n",
       "  0.1984322965145111,\n",
       "  0.09720142930746078,\n",
       "  0.19747667014598846,\n",
       "  0.11499760299921036,\n",
       "  0.08300044387578964,\n",
       "  0.04516167566180229,\n",
       "  0.3643701672554016,\n",
       "  0.047653209418058395,\n",
       "  0.015978945419192314,\n",
       "  0.05938476324081421,\n",
       "  0.10690011084079742,\n",
       "  0.10779966413974762,\n",
       "  0.1301550269126892,\n",
       "  0.4695601761341095,\n",
       "  0.024486316367983818,\n",
       "  0.029603488743305206,\n",
       "  0.18390029668807983,\n",
       "  0.03571487218141556,\n",
       "  0.106218621134758,\n",
       "  0.07692262530326843,\n",
       "  0.04396110028028488,\n",
       "  0.13973791897296906,\n",
       "  0.022229846566915512,\n",
       "  0.7686766386032104,\n",
       "  0.05500587821006775,\n",
       "  0.16776728630065918,\n",
       "  0.1520301103591919,\n",
       "  0.36724430322647095,\n",
       "  0.0681963860988617,\n",
       "  0.06987558305263519,\n",
       "  0.4611569941043854,\n",
       "  0.07041674852371216,\n",
       "  0.4539085924625397,\n",
       "  0.015247851610183716,\n",
       "  0.025699017569422722,\n",
       "  0.10587850213050842,\n",
       "  0.045182742178440094,\n",
       "  0.014100516214966774,\n",
       "  0.01480979286134243,\n",
       "  0.5928453803062439,\n",
       "  0.059853315353393555,\n",
       "  0.056090567260980606,\n",
       "  0.055478066205978394,\n",
       "  0.05028176307678223,\n",
       "  0.02776285633444786,\n",
       "  0.0049720690585672855,\n",
       "  0.025820396840572357,\n",
       "  0.003953523933887482,\n",
       "  0.012088644318282604,\n",
       "  0.18823012709617615,\n",
       "  0.006824428215622902,\n",
       "  0.013598529621958733,\n",
       "  0.009137570858001709,\n",
       "  0.009584246203303337,\n",
       "  0.01779882237315178,\n",
       "  0.4545014500617981,\n",
       "  0.030038120225071907,\n",
       "  0.008546903729438782,\n",
       "  0.014275101944804192,\n",
       "  0.03480566293001175,\n",
       "  0.7875397801399231,\n",
       "  0.09448588639497757,\n",
       "  0.05396636202931404,\n",
       "  0.023571809753775597,\n",
       "  0.02418270707130432,\n",
       "  0.02787422202527523,\n",
       "  0.040108710527420044,\n",
       "  0.028264043852686882,\n",
       "  0.011014113202691078,\n",
       "  0.18050813674926758,\n",
       "  0.09170128405094147,\n",
       "  0.008163513615727425,\n",
       "  0.02811862714588642,\n",
       "  0.01206224039196968,\n",
       "  0.0073537155985832214,\n",
       "  0.005786188878118992,\n",
       "  0.034792132675647736,\n",
       "  0.1116381585597992,\n",
       "  0.004870707634836435,\n",
       "  0.008973424322903156,\n",
       "  0.0033356535714119673,\n",
       "  0.01594037190079689,\n",
       "  0.005446747876703739,\n",
       "  0.0060824076645076275,\n",
       "  0.001658615656197071,\n",
       "  0.10569392144680023,\n",
       "  0.12029653787612915,\n",
       "  0.001271908637136221,\n",
       "  0.002503561321645975,\n",
       "  0.05127401277422905,\n",
       "  0.04277697205543518,\n",
       "  0.00173352868296206,\n",
       "  0.06705157458782196,\n",
       "  0.0037309210747480392,\n",
       "  0.0016870584804564714,\n",
       "  0.0035834989976137877,\n",
       "  0.0803275778889656,\n",
       "  0.006310019642114639,\n",
       "  2.361097574234009,\n",
       "  0.0020318382885307074,\n",
       "  0.006343396846204996,\n",
       "  0.1643667072057724,\n",
       "  1.0922422409057617,\n",
       "  0.039276838302612305,\n",
       "  0.008763057179749012,\n",
       "  0.10470779240131378,\n",
       "  0.04407079890370369,\n",
       "  0.02695360966026783,\n",
       "  0.12720979750156403,\n",
       "  0.09959351271390915,\n",
       "  0.018111582845449448,\n",
       "  0.05184296518564224,\n",
       "  0.10550033301115036,\n",
       "  0.2237233966588974,\n",
       "  0.04594529792666435,\n",
       "  0.03561534360051155,\n",
       "  0.10103996843099594,\n",
       "  0.27339819073677063,\n",
       "  0.016979478299617767,\n",
       "  0.08716022968292236,\n",
       "  0.14679841697216034,\n",
       "  0.17888765037059784,\n",
       "  0.2473524510860443,\n",
       "  0.13412915170192719,\n",
       "  0.1450347900390625,\n",
       "  0.06820789724588394,\n",
       "  0.01320297084748745,\n",
       "  0.11345291882753372,\n",
       "  0.03814854472875595,\n",
       "  0.012147725559771061,\n",
       "  0.033060554414987564,\n",
       "  0.10826414823532104,\n",
       "  0.4020020663738251,\n",
       "  0.03746837005019188,\n",
       "  0.061120446771383286,\n",
       "  0.04989809915423393,\n",
       "  0.004575563129037619,\n",
       "  0.03028183802962303,\n",
       "  0.029238583520054817,\n",
       "  0.006358634680509567,\n",
       "  0.003363690571859479,\n",
       "  0.021388636901974678,\n",
       "  0.00453915074467659,\n",
       "  0.009342803619801998,\n",
       "  0.02815614826977253,\n",
       "  0.002201670315116644,\n",
       "  0.025995993986725807,\n",
       "  0.012054837308824062,\n",
       "  0.07084953784942627,\n",
       "  0.10501686483621597,\n",
       "  0.05914175510406494,\n",
       "  0.1569209098815918,\n",
       "  0.0022949110716581345,\n",
       "  0.015810079872608185,\n",
       "  0.6150146126747131,\n",
       "  0.2915852665901184,\n",
       "  0.12856446206569672,\n",
       "  0.0031544773373752832,\n",
       "  0.00041886730468831956,\n",
       "  0.4027535319328308,\n",
       "  0.0009301500977016985,\n",
       "  0.002301541157066822,\n",
       "  0.003118485677987337,\n",
       "  0.11012005060911179,\n",
       "  0.0029451576992869377,\n",
       "  0.15779118239879608,\n",
       "  0.007442759349942207,\n",
       "  0.0030173512641340494,\n",
       "  0.0015432214131578803,\n",
       "  0.2828773856163025,\n",
       "  0.05393761023879051,\n",
       "  0.28695768117904663,\n",
       "  0.06913512200117111,\n",
       "  0.014523342251777649,\n",
       "  0.014864543452858925,\n",
       "  0.18451634049415588,\n",
       "  0.2808617949485779,\n",
       "  0.0018429206684231758,\n",
       "  0.009448668919503689,\n",
       "  0.2751528024673462,\n",
       "  0.016143150627613068,\n",
       "  0.010216070339083672,\n",
       "  0.6187869906425476,\n",
       "  0.015160870738327503,\n",
       "  0.09673294425010681,\n",
       "  0.09438373893499374,\n",
       "  0.22473305463790894,\n",
       "  0.009690076112747192,\n",
       "  0.21602031588554382,\n",
       "  0.3439209759235382,\n",
       "  0.10691004991531372,\n",
       "  0.1712971031665802,\n",
       "  0.002541861729696393,\n",
       "  0.018956828862428665,\n",
       "  0.00907856598496437,\n",
       "  0.01212049089372158,\n",
       "  0.028918446972966194,\n",
       "  0.0640614777803421,\n",
       "  0.058773402124643326,\n",
       "  0.01867716573178768,\n",
       "  0.0029847233090549707,\n",
       "  0.05417480692267418,\n",
       "  0.0018532541580498219,\n",
       "  0.022656025364995003,\n",
       "  0.11585140973329544,\n",
       "  0.006876882631331682,\n",
       "  0.006788045167922974,\n",
       "  0.00433447165414691,\n",
       "  0.02140101231634617,\n",
       "  0.001732609118334949,\n",
       "  0.00467129610478878,\n",
       "  0.22060410678386688,\n",
       "  0.0021235207095742226,\n",
       "  0.012485983781516552,\n",
       "  1.0032387971878052,\n",
       "  0.40766724944114685,\n",
       "  0.019934341311454773,\n",
       "  0.5054993033409119,\n",
       "  0.01112570520490408,\n",
       "  0.016215156763792038,\n",
       "  0.023936090990900993,\n",
       "  0.0020336266607046127,\n",
       "  0.04557877033948898,\n",
       "  0.0028016918804496527,\n",
       "  0.027342544868588448,\n",
       "  0.010637030936777592,\n",
       "  0.24583682417869568,\n",
       "  0.8143667578697205,\n",
       "  0.008743365295231342,\n",
       "  0.13382850587368011,\n",
       "  0.010551647283136845,\n",
       "  0.015631698071956635,\n",
       "  0.04240041226148605,\n",
       "  0.05762246996164322,\n",
       "  0.7593700289726257,\n",
       "  0.03886372968554497,\n",
       "  0.013023162260651588,\n",
       "  0.019207755103707314,\n",
       "  0.026574674993753433,\n",
       "  0.05468377098441124,\n",
       "  0.08852025866508484,\n",
       "  0.19230356812477112,\n",
       "  0.04801337793469429,\n",
       "  0.03955001384019852,\n",
       "  0.05387537181377411,\n",
       "  0.32138165831565857,\n",
       "  0.1001206785440445,\n",
       "  0.04434313625097275,\n",
       "  0.041134148836135864,\n",
       "  0.05389771983027458,\n",
       "  0.005195521283894777,\n",
       "  0.20263409614562988,\n",
       "  0.35292840003967285,\n",
       "  0.014478804543614388,\n",
       "  0.009792715311050415,\n",
       "  0.010238012298941612,\n",
       "  0.005253314971923828,\n",
       "  0.004311685916036367,\n",
       "  0.006797152105718851,\n",
       "  0.020701102912425995,\n",
       "  0.0014979734551161528,\n",
       "  0.048322372138500214,\n",
       "  0.08074070513248444,\n",
       "  0.0416710339486599,\n",
       "  0.004079575650393963,\n",
       "  0.005339532624930143,\n",
       "  0.015382688492536545,\n",
       "  0.011509058997035027,\n",
       "  0.01689482480287552,\n",
       "  0.0007373710977844894,\n",
       "  0.026744872331619263,\n",
       "  0.0010868363315239549,\n",
       "  0.5229505300521851,\n",
       "  0.00429468834772706,\n",
       "  0.012435860931873322,\n",
       "  0.002098902128636837,\n",
       "  0.007328295148909092,\n",
       "  0.018334709107875824,\n",
       "  0.0006403613951988518,\n",
       "  0.0015369178727269173,\n",
       "  0.007071914151310921,\n",
       "  0.3190482258796692,\n",
       "  0.00796223059296608,\n",
       "  0.006549502722918987,\n",
       "  0.030514229089021683,\n",
       "  0.07232291251420975,\n",
       "  0.030600355938076973,\n",
       "  0.09899342060089111,\n",
       "  0.019487498328089714,\n",
       "  0.001396799460053444,\n",
       "  0.10069214552640915,\n",
       "  0.007758831139653921,\n",
       "  0.01090780459344387,\n",
       "  0.0018751469906419516,\n",
       "  0.006577686406672001,\n",
       "  0.0016145471017807722,\n",
       "  0.0005287512321956456,\n",
       "  0.005555812735110521,\n",
       "  0.018423812463879585,\n",
       "  0.0024663677904754877,\n",
       "  0.004198168870061636,\n",
       "  0.01975470595061779,\n",
       "  0.0006552123813889921,\n",
       "  0.018964137881994247,\n",
       "  0.0008742072386667132,\n",
       "  0.005669295322149992,\n",
       "  0.0008476465009152889,\n",
       "  0.007281527854502201,\n",
       "  0.012988810427486897,\n",
       "  0.0015025980537757277,\n",
       "  0.010622329078614712,\n",
       "  0.0008119699778035283,\n",
       "  0.0008961100829765201,\n",
       "  0.0004383864579722285,\n",
       "  0.0025455462746322155,\n",
       "  0.5569990873336792,\n",
       "  0.001823754282668233,\n",
       "  0.006903512869030237,\n",
       "  0.026194507256150246,\n",
       "  0.08715608716011047,\n",
       "  0.01059630699455738,\n",
       "  2.3245382180903107e-05,\n",
       "  0.005986473988741636,\n",
       "  0.00034278538078069687,\n",
       "  0.005884266458451748,\n",
       "  0.00014806709077674896,\n",
       "  0.002533992752432823,\n",
       "  0.006195871625095606,\n",
       "  0.0035343472845852375,\n",
       "  0.001409047283232212,\n",
       "  0.08029408752918243,\n",
       "  0.0004503207455854863,\n",
       "  0.00047940673539415,\n",
       "  0.0058524454943835735,\n",
       "  0.0036122368182986975,\n",
       "  0.017138581722974777,\n",
       "  0.020502639934420586,\n",
       "  7.254786760313436e-05,\n",
       "  0.0005394157487899065,\n",
       "  0.003214506898075342,\n",
       "  0.01794539764523506,\n",
       "  0.00011265779176028445,\n",
       "  0.0009183763759210706,\n",
       "  0.30084916949272156,\n",
       "  0.0009478376596234739,\n",
       "  0.17416635155677795,\n",
       "  0.0001441576168872416,\n",
       "  7.618164818268269e-05,\n",
       "  0.03902323171496391,\n",
       "  0.06326472014188766,\n",
       "  0.010190668515861034,\n",
       "  0.08193272352218628,\n",
       "  0.00027413255884312093,\n",
       "  0.00640869839116931,\n",
       "  0.012359419837594032,\n",
       "  0.00034617833443917334,\n",
       "  0.012888235040009022,\n",
       "  0.0029551489278674126,\n",
       "  0.0008621267043054104,\n",
       "  0.0030533229000866413,\n",
       "  0.021069731563329697,\n",
       "  0.013745839707553387,\n",
       "  0.007246673107147217,\n",
       "  0.06625974923372269,\n",
       "  0.001680237241089344,\n",
       "  0.017198916524648666,\n",
       "  0.0010773674584925175,\n",
       "  0.004273696802556515,\n",
       "  0.017196137458086014,\n",
       "  0.0024991303216665983,\n",
       "  0.014426611363887787,\n",
       "  0.0025452214758843184,\n",
       "  0.0015722746029496193,\n",
       "  0.0009789803298190236,\n",
       "  0.0006030679796822369,\n",
       "  0.001201738603413105,\n",
       "  0.004667069762945175,\n",
       "  0.00019246558076702058,\n",
       "  0.0009096169378608465,\n",
       "  0.00040421701851300895,\n",
       "  0.029429977759718895,\n",
       "  0.004160400480031967,\n",
       "  0.0009829605696722865,\n",
       "  0.0007929480052553117,\n",
       "  0.008138205856084824,\n",
       "  0.06596538424491882,\n",
       "  0.0032386963721364737,\n",
       "  0.0007960736402310431,\n",
       "  0.0006531457183882594,\n",
       "  0.0007513024029321969,\n",
       "  0.005614931229501963,\n",
       "  0.00011336390161886811,\n",
       "  0.00016801389574538916,\n",
       "  0.0002540488203521818,\n",
       "  0.00034488714300096035,\n",
       "  0.0045988792553544044,\n",
       "  0.00013399106683209538,\n",
       "  0.0026731095276772976,\n",
       "  0.01637886092066765,\n",
       "  0.02143396995961666,\n",
       "  0.0011473490158095956,\n",
       "  0.0006121161277405918,\n",
       "  3.784740329138003e-05,\n",
       "  0.00819430872797966,\n",
       "  0.005460511427372694,\n",
       "  0.00013039879559073597,\n",
       "  0.00019570473523344845,\n",
       "  6.400961865438148e-05,\n",
       "  0.01385924406349659,\n",
       "  0.014620879665017128,\n",
       "  0.0013951616128906608,\n",
       "  0.00019018563034478575,\n",
       "  0.00011032230395358056,\n",
       "  0.00021409723558463156,\n",
       "  0.00019309016352053732,\n",
       "  0.0023046177811920643,\n",
       "  0.00023197248810902238,\n",
       "  4.3955438741249964e-05,\n",
       "  8.321149653056636e-05,\n",
       "  0.000792813312727958,\n",
       "  0.0010511622531339526,\n",
       "  0.00019853581034112722,\n",
       "  0.0001385863870382309,\n",
       "  0.027374787256121635,\n",
       "  0.0003248521825298667,\n",
       "  9.917966235661879e-05,\n",
       "  0.05057074502110481,\n",
       "  0.000630188558716327,\n",
       "  0.00018650175479706377,\n",
       "  0.0002036496007349342,\n",
       "  0.0023122248239815235,\n",
       "  0.017192352563142776,\n",
       "  8.185890328604728e-05,\n",
       "  0.015080650337040424,\n",
       "  3.710150485858321e-05,\n",
       "  0.0003931510145775974,\n",
       "  2.7745063562178984e-05,\n",
       "  0.00020018487703055143,\n",
       "  0.0004460517084226012,\n",
       "  0.0002587927447166294,\n",
       "  0.0009453616803511977,\n",
       "  0.00015857332618907094,\n",
       "  0.0012822054559364915,\n",
       "  0.00039021464181132615,\n",
       "  0.05236639082431793,\n",
       "  0.00010885503434110433,\n",
       "  0.00021210404520388693,\n",
       "  2.4377679437748156e-05,\n",
       "  0.02636544406414032,\n",
       "  8.267150406027213e-05,\n",
       "  0.0012109362287446856,\n",
       "  0.00015830676420591772,\n",
       "  0.011198797263205051,\n",
       "  6.690013833576813e-05,\n",
       "  0.00011836497287731618,\n",
       "  8.794517634669319e-05,\n",
       "  0.000167826670804061,\n",
       "  0.00552599411457777,\n",
       "  2.175520967284683e-05,\n",
       "  0.00011601347796386108,\n",
       "  0.0011288999812677503,\n",
       "  0.00010736023250501603,\n",
       "  0.00048276945017278194,\n",
       "  0.0003324802382849157,\n",
       "  0.0004573047917801887,\n",
       "  0.0002476535737514496,\n",
       "  4.4998763769399375e-05,\n",
       "  0.00014672757242806256,\n",
       "  0.00014838550123386085,\n",
       "  0.00025039465981535614,\n",
       "  0.0006153316353447735,\n",
       "  0.00016439895262010396,\n",
       "  0.911808967590332,\n",
       "  0.00016670273907948285,\n",
       "  0.000873980054166168,\n",
       "  0.001860864576883614,\n",
       "  0.004643171094357967,\n",
       "  0.003885198850184679,\n",
       "  0.05826924741268158,\n",
       "  0.0009527647634968162,\n",
       "  0.0008502363343723118,\n",
       "  0.0018791388720273972,\n",
       "  0.533931314945221,\n",
       "  0.0012542498297989368,\n",
       "  0.0002730115666054189,\n",
       "  0.020857172086834908,\n",
       "  0.10660621523857117,\n",
       "  0.0009389396873302758,\n",
       "  0.0010797504801303148,\n",
       "  0.09648611396551132,\n",
       "  0.00028937350725755095,\n",
       "  0.0027343269903212786,\n",
       "  0.22218318283557892,\n",
       "  0.00043232989264652133,\n",
       "  0.0006803376600146294,\n",
       "  0.00023947557201609015,\n",
       "  0.0027861339040100574,\n",
       "  0.0780421793460846,\n",
       "  0.0129891661927104,\n",
       "  0.00023714669805485755,\n",
       "  0.027438227087259293,\n",
       "  0.007385884411633015,\n",
       "  0.0011176419211551547,\n",
       "  0.0013332533417269588,\n",
       "  0.005103791132569313,\n",
       "  0.5305519104003906,\n",
       "  0.0015975992428138852,\n",
       "  0.008995169773697853,\n",
       "  0.3995469808578491,\n",
       "  0.002556895138695836,\n",
       "  0.013631370849907398,\n",
       "  0.00106424477417022,\n",
       "  0.004672060254961252,\n",
       "  0.0015250103315338492,\n",
       "  0.004789857659488916,\n",
       "  0.0029284677002578974,\n",
       "  0.1753309965133667,\n",
       "  0.0008583925664424896,\n",
       "  0.0009202949004247785,\n",
       "  0.008897535502910614,\n",
       "  0.03425609692931175,\n",
       "  0.023971565067768097,\n",
       "  0.1813218593597412,\n",
       "  0.0034885958302766085,\n",
       "  0.46056920289993286,\n",
       "  0.0015625638188794255,\n",
       "  0.2537410259246826,\n",
       "  0.008160214871168137,\n",
       "  0.00012284006515983492,\n",
       "  0.022443952038884163,\n",
       "  0.3766132593154907,\n",
       "  0.5528509616851807,\n",
       "  0.005675009451806545,\n",
       "  0.3584088087081909,\n",
       "  0.1735774278640747,\n",
       "  0.0015672874869778752,\n",
       "  0.16631044447422028,\n",
       "  0.04214233160018921,\n",
       "  0.008532533422112465,\n",
       "  0.008769403211772442,\n",
       "  0.002951601520180702,\n",
       "  0.11985992640256882,\n",
       "  0.4293651282787323,\n",
       "  0.0012624734081327915,\n",
       "  0.040480829775333405,\n",
       "  1.0012673139572144,\n",
       "  0.034025710076093674,\n",
       "  0.00250439066439867,\n",
       "  0.018757952377200127,\n",
       "  0.00416559400036931,\n",
       "  0.5464670062065125,\n",
       "  0.001513374038040638,\n",
       "  0.14653794467449188,\n",
       "  0.002856193808838725,\n",
       "  0.2858366370201111,\n",
       "  0.21141782402992249,\n",
       "  0.7706178426742554,\n",
       "  0.0911082848906517,\n",
       "  0.01018588524311781,\n",
       "  0.019516997039318085,\n",
       "  0.041043028235435486,\n",
       "  0.3994930684566498,\n",
       "  0.007678050547838211,\n",
       "  0.07966196537017822,\n",
       "  0.1898067444562912,\n",
       "  0.01385620329529047,\n",
       "  0.004592799581587315,\n",
       "  0.042830780148506165,\n",
       "  0.007390957325696945,\n",
       "  0.009369030594825745,\n",
       "  0.008568251505494118,\n",
       "  0.0047279042191803455,\n",
       "  0.007733615580946207,\n",
       "  0.005889064632356167,\n",
       "  0.0026731211692094803,\n",
       "  0.010552841238677502,\n",
       "  0.05442998558282852,\n",
       "  0.023722583428025246,\n",
       "  0.045944198966026306,\n",
       "  0.03569531440734863,\n",
       "  0.01134523842483759,\n",
       "  0.026518696919083595,\n",
       "  0.011572951450943947,\n",
       "  0.011853638105094433,\n",
       "  0.02164526656270027,\n",
       "  0.0020757182501256466,\n",
       "  0.0019406659994274378,\n",
       "  0.013974092900753021,\n",
       "  0.008635099045932293,\n",
       "  0.8914207816123962,\n",
       "  0.004578441381454468,\n",
       "  0.00048036722000688314,\n",
       "  0.001147475908510387,\n",
       "  0.0019479923648759723,\n",
       "  0.17627578973770142,\n",
       "  0.007278083823621273,\n",
       "  0.003890722757205367,\n",
       "  0.007203396875411272,\n",
       "  0.0075932713225483894,\n",
       "  0.10826615989208221,\n",
       "  0.002198189962655306,\n",
       "  0.0012122858315706253,\n",
       "  0.006628183647990227,\n",
       "  0.04269695654511452,\n",
       "  0.005883028265088797,\n",
       "  0.24751873314380646,\n",
       "  0.0004960515652783215,\n",
       "  0.0016030812403187156,\n",
       "  0.18194614350795746,\n",
       "  0.006697248667478561,\n",
       "  0.001513381372205913,\n",
       "  0.0025238567031919956,\n",
       "  0.002238726941868663,\n",
       "  0.005983419716358185,\n",
       "  0.007768446579575539,\n",
       "  0.009584305807948112,\n",
       "  0.12688466906547546,\n",
       "  0.0021516764536499977,\n",
       "  0.019931090995669365,\n",
       "  0.010084668174386024,\n",
       "  0.0030098059214651585,\n",
       "  0.00042395698255859315,\n",
       "  0.0017459774389863014,\n",
       "  0.0008749061962589622,\n",
       "  0.0005127667682245374,\n",
       "  0.0074567790143191814,\n",
       "  0.0004531604645308107,\n",
       "  0.0023639469873160124,\n",
       "  0.004030605778098106,\n",
       "  0.0021775742061436176,\n",
       "  0.003863575169816613,\n",
       "  0.0006743062986060977,\n",
       "  0.018810685724020004,\n",
       "  0.0008505439036525786,\n",
       "  0.00456462474539876,\n",
       "  1.012794017791748,\n",
       "  0.0005326454993337393,\n",
       "  0.029984384775161743,\n",
       "  0.002591762924566865,\n",
       "  0.0006362653221003711,\n",
       "  0.007540120743215084,\n",
       "  0.0037390021607279778,\n",
       "  0.0019128588028252125,\n",
       "  0.027606992051005363,\n",
       "  0.0013041467173025012,\n",
       "  0.006199968513101339,\n",
       "  0.007038377225399017,\n",
       "  0.002503433031961322,\n",
       "  0.0009866433683782816,\n",
       "  0.2188970148563385,\n",
       "  0.0006243528914637864,\n",
       "  0.07898490130901337,\n",
       "  0.0026075325440615416,\n",
       "  0.020445454865694046,\n",
       "  0.12801364064216614,\n",
       "  0.010277936235070229,\n",
       "  0.01997440494596958,\n",
       "  0.017669884487986565,\n",
       "  0.003031237283721566,\n",
       "  0.04394926130771637,\n",
       "  0.001030226587317884,\n",
       "  0.2896190881729126,\n",
       "  0.0031010457314550877,\n",
       "  0.01142386719584465,\n",
       "  0.12344738841056824,\n",
       "  0.0008094584918580949,\n",
       "  0.015967635437846184,\n",
       "  0.002856798004359007,\n",
       "  0.0005832716706208885,\n",
       "  0.008811344392597675,\n",
       "  0.0012983963824808598,\n",
       "  0.0005177044658921659,\n",
       "  0.0024098819121718407,\n",
       "  0.001682712696492672,\n",
       "  0.001474353251978755,\n",
       "  0.00031118342303670943,\n",
       "  0.013072273693978786,\n",
       "  0.00040619337232783437,\n",
       "  0.0025610080920159817,\n",
       "  0.05372007191181183,\n",
       "  0.0032414065208286047,\n",
       "  0.0030825831927359104,\n",
       "  0.00014342252688948065,\n",
       "  0.0015797868836671114,\n",
       "  0.0003903514298144728,\n",
       "  0.011340227909386158,\n",
       "  0.0005811367882415652,\n",
       "  0.02879491075873375,\n",
       "  0.06368324905633926,\n",
       "  0.06607017666101456,\n",
       "  0.00186239555478096,\n",
       "  0.004114528186619282,\n",
       "  0.0024407024029642344,\n",
       "  0.00732512166723609,\n",
       "  0.0010372732067480683,\n",
       "  0.011148515157401562,\n",
       "  0.006483076140284538,\n",
       "  0.009030788205564022,\n",
       "  0.00024337969080079347,\n",
       "  0.02790377289056778,\n",
       "  0.0019527667900547385,\n",
       "  5.3027993999421597e-05,\n",
       "  0.003974369261413813,\n",
       "  0.00570277776569128,\n",
       "  0.003601155010983348,\n",
       "  7.322261808440089e-05,\n",
       "  0.001368101336993277,\n",
       "  6.174376903800294e-05,\n",
       "  0.001499103382229805,\n",
       "  0.0904446393251419,\n",
       "  0.001047395751811564,\n",
       "  0.00023356452584266663,\n",
       "  0.0034896221477538347,\n",
       "  0.000649217632599175,\n",
       "  1.066986083984375,\n",
       "  0.00028666018624790013,\n",
       "  0.00011128943879157305,\n",
       "  0.0007480207132175565,\n",
       "  0.0032966758590191603,\n",
       "  0.006969590205699205,\n",
       "  0.12840302288532257,\n",
       "  0.0012678410857915878,\n",
       "  0.0010017456952482462,\n",
       "  0.002528977580368519,\n",
       "  0.06645940989255905,\n",
       "  0.022066442295908928,\n",
       "  0.00906719733029604,\n",
       "  0.4946516454219818,\n",
       "  0.031099628657102585,\n",
       "  0.0006024989997968078,\n",
       "  0.2921464145183563,\n",
       "  0.001542749349027872,\n",
       "  0.004959952086210251,\n",
       "  0.03187447786331177,\n",
       "  0.0038397994358092546,\n",
       "  0.0009633498266339302,\n",
       "  0.0018905963515862823,\n",
       "  0.028005817905068398,\n",
       "  0.35669195652008057,\n",
       "  0.030159790068864822,\n",
       "  0.02345641702413559,\n",
       "  0.5190974473953247,\n",
       "  0.01724061742424965,\n",
       "  0.018061961978673935,\n",
       "  0.45734965801239014,\n",
       "  0.003554133465513587,\n",
       "  0.01237797737121582,\n",
       "  0.45729392766952515,\n",
       "  0.03316478058695793,\n",
       "  0.005056397989392281,\n",
       "  0.00245447619818151,\n",
       "  0.002463094424456358,\n",
       "  0.0020951435435563326,\n",
       "  0.0048589580692350864,\n",
       "  0.00484466552734375,\n",
       "  0.09869441390037537,\n",
       "  0.3247317671775818,\n",
       "  0.02282455936074257,\n",
       "  0.01760149374604225,\n",
       "  0.02082016132771969,\n",
       "  0.0029324188362807035,\n",
       "  0.016130121424794197],\n",
       " [0.83,\n",
       "  0.82,\n",
       "  0.89,\n",
       "  0.93,\n",
       "  0.82,\n",
       "  0.98,\n",
       "  0.97,\n",
       "  0.99,\n",
       "  0.95,\n",
       "  0.97,\n",
       "  1.0,\n",
       "  0.76,\n",
       "  1.0,\n",
       "  0.96,\n",
       "  0.65,\n",
       "  0.97,\n",
       "  0.99,\n",
       "  1.0,\n",
       "  0.99,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.99,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.96,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.train(train_data_n, oversample_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_data_n, batch_size=42, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, labels = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model3.infer(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels == preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30/42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f32023d3187841795697d47a9066836f1d96daf3799e179b4995fcdf98db168e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
